{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMl-e49Is7-8",
        "outputId": "8a169b22-16e0-4780-ccc4-1e06055d8a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r3MpHK8vbYds"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random, math, glob, copy, pickle, warnings\n",
        "from time import process_time\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqgGY9I9ZzDs"
      },
      "source": [
        "# Feature Dropping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yvOs5BLJZyex"
      },
      "outputs": [],
      "source": [
        "def dropping(x_vector, y_vector, input_percentage):\n",
        "    #global mi_pcc, mi_pcc_sort\n",
        "    # remove the lowest k percentage features from mi_pcc\n",
        "    cutoff = int(math.floor(input_percentage*(x_vector.shape[1])))\n",
        "\n",
        "    fecture_vector = list(x_vector.columns)\n",
        "    removed_feature_list, selected_features = [], []\n",
        "    for i in range(0, cutoff):\n",
        "      for j in range(0, mi_pcc_sort.shape[0]):\n",
        "            if(mi_pcc_sort[i]==mi_pcc[j]):\n",
        "                removed_feature_list.append(fecture_vector[j])\n",
        "    \n",
        "    for k in fecture_vector:\n",
        "        st = 1\n",
        "        for i in removed_feature_list:\n",
        "            if(i==k):\n",
        "                st = 0\n",
        "                break\n",
        "        if(st==1):\n",
        "            selected_features.append(k)\n",
        "    \n",
        "    data = x_vector[selected_features]\n",
        "\n",
        "    mi_selected_features = mutual_info_classif(data, y_vector)\n",
        "    return data, mi_selected_features\n",
        "def hybrid(x_vector, y_vector, percentage):\n",
        "    \"\"\"\n",
        "    Input:  x_vector: 2D array shape of (no_of_samples, no_of_features)\n",
        "            y_vector: 1D array shape of (no_of_sample, )\n",
        "    Output: data: which is equal to x_vector shape of (no_of_samples, no_of_selected_features)\n",
        "    Functionality:  Select the top k percentage of features based on mi and pcc.\n",
        "                    Adopted from paper: https://sci-hub.se/10.1109/calcon49167.2020.9106516\n",
        "    \"\"\"\n",
        "    #global mi_selected_features\n",
        "    global sort_features_list, mi_pcc, mi_pcc_sort\n",
        "\n",
        "    feature_pcc, selected_features, removed_feature_list = [], [], []\n",
        "    a = 0.9\n",
        "    \n",
        "    # Drop constant features\n",
        "    x_vector = x_vector.loc[:,x_vector.apply(pd.Series.nunique) != 1]\n",
        "\n",
        "    # calculate the mutual information between class and feature vector\n",
        "    mi = mutual_info_classif(x_vector, y_vector)\n",
        "\n",
        "    # calculate the pcc between feature to feature\n",
        "    fecture_vector = list(x_vector.columns)\n",
        "    corr_matrix = x_vector.corr()\n",
        "    corr_matrix = abs(np.array(corr_matrix))\n",
        "    for i in range(0, len(corr_matrix)):\n",
        "        feature_pcc.append((np.sum(corr_matrix[i]) - 1)/(len(corr_matrix)-1))\n",
        "    \n",
        "    # compute the final rank value for feature vector\n",
        "    mi_pcc = a*mi - (1-a)*np.array(feature_pcc)\n",
        "\n",
        "    # remove the lowest k percentage features from mi_pcc\n",
        "    cutoff = int(math.floor(percentage*(x_vector.shape[1])))\n",
        "\n",
        "    # sort the array in ascending order\n",
        "    mi_pcc_sort = mi_pcc.copy()\n",
        "    mi_pcc_sort.sort()\n",
        "\n",
        "    sort_features_list = []\n",
        "    mi_sorted = []\n",
        "    for i in range(0, mi_pcc_sort.shape[0]):\n",
        "        for j in range(0, mi_pcc.shape[0]):\n",
        "            if(mi_pcc_sort[i]==mi_pcc[j]):\n",
        "                sort_features_list.append(fecture_vector[j])\n",
        "                #mi_sorted.append()\n",
        "                mi_pcc[j] = 100000000\n",
        "                break\n",
        "    \n",
        "    \n",
        "    removed_feature_list = sort_features_list[0:cutoff]\n",
        "    selected_features = sort_features_list[cutoff:]\n",
        "    \n",
        "    print(\"No of removed features: \", len(removed_feature_list))\n",
        "    print(\"No of selected features: \", len(selected_features))\n",
        "    if(x_vector.shape[1]>1000):\n",
        "        # microarray dataset\n",
        "        pass\n",
        "    else:\n",
        "        print(\"Deleted feature vectors list: \", removed_feature_list)\n",
        "        print(\"Selected feature vectors list: \", selected_features)\n",
        "\n",
        "    # create the x data based on selected feature vector\n",
        "    data = x_vector[selected_features]\n",
        "\n",
        "    \"\"\"\n",
        "    compute the mutual information of the selected feature vector.\n",
        "    which will be using as an 3rd obejectine function for the GA and SA.\n",
        "    \"\"\"\n",
        "    mi_selected_features = mutual_info_classif(data, y_vector)\n",
        "    return data, mi_selected_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jGnUyDbuGIj9"
      },
      "outputs": [],
      "source": [
        "def check_overlapping_for_cluster(pop):\n",
        "    \"\"\"\n",
        "    Input: population, population_fitness, population_accuracy\n",
        "    Output: population, population_fitness, population_accuracy\n",
        "    Functionality:  Takes an population and checks if there are\n",
        "                    multiple copies of a individual then remove\n",
        "                    all these copies.\n",
        "    \"\"\"\n",
        "    enable_output = False # to show the results\n",
        "    pop_copy = pop.copy()\n",
        "    remove_index = []\n",
        "    for i in range(0, len(pop)):\n",
        "        counter = i\n",
        "        for j in pop[i+1:]:\n",
        "            counter += 1\n",
        "            \"\"\"\n",
        "            If two individuals are same then store these same\n",
        "            indiviual's index number for delete.\n",
        "            \"\"\"\n",
        "            if(isEqual(pop[i], j)):\n",
        "                remove_index.append(counter)\n",
        "    remove_index = list(set(remove_index))\n",
        "    remove_index.sort(reverse = True)\n",
        "    \n",
        "    # delete the copy individuals from populations\n",
        "    for i in remove_index:\n",
        "        del pop_copy[i]\n",
        "    \n",
        "    if(enable_output):\n",
        "        if(len(pop_copy) == len(pop)):\n",
        "            print(\"\\nNo overlapping has been occured!!\")\n",
        "            print(\"Current population size: \", len(pop_copy))\n",
        "        else:\n",
        "            print(\"Overlapping occured. Current population size: \", len(pop_copy))\n",
        "    \n",
        "    return pop_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VgKDBt7uGRBZ"
      },
      "outputs": [],
      "source": [
        "def hammingDist(ind1, ind2):\n",
        "    \"\"\"\n",
        "    Input: two individual ind1 and ind2\n",
        "    Output: an integer value\n",
        "    Functionality: compute the hamming distance between two individuals\n",
        "    \"\"\"\n",
        "    i, count = 0, 0\n",
        "    while(i < len(ind1)):\n",
        "        if(ind1[i] != ind2[i]):\n",
        "            count += 1\n",
        "        i += 1\n",
        "    return count\n",
        "\n",
        "def cal_similarity(ind_datapoint, cluster_datapoint, ind_acc, cluster_acc):\n",
        "    esp = 0.7\n",
        "    # compute the hamming distance between the cluster_datapoint and ind_datapoint\n",
        "    hamming_dist = hammingDist(cluster_datapoint, ind_datapoint)\n",
        "    # difference between classification accuracy\n",
        "    diff_acc = abs(ind_acc-cluster_acc)\n",
        "    similarity = esp*(1/diff_acc) + (1-esp)*(1/hamming_dist)\n",
        "    return similarity\n",
        "\n",
        "def get_random_pop(size):\n",
        "    random_population = []\n",
        "    for i in range(0, size):\n",
        "        random_population.append(get_individual())\n",
        "    # check there is any overlapping in between or not\n",
        "    random_population = check_overlapping_for_cluster(random_population)\n",
        "    return random_population\n",
        "\n",
        "\n",
        "def CBPI(population_size):\n",
        "    \"\"\"\n",
        "    Input: an 2D array of shape (population_size, no_of_features)\n",
        "    Output: an 2D array of shape (population_size, no_of_features)\n",
        "    Functionality: Cluster based population generation\n",
        "    \"\"\"\n",
        "    population, population_fit, population_acc = [], [], []\n",
        "    random_pop = get_random_pop(4*population_size)\n",
        "    no_cluster_center = population_size # m = no_cluster_center i.e. should be \n",
        "    \n",
        "    \"\"\"\n",
        "    Randomly Initialize the cluster center\n",
        "    \"\"\"\n",
        "    cluster_centers = random.sample(random_pop, no_cluster_center)\n",
        "\n",
        "    \"\"\"\n",
        "    now discard the cluster centers individuals from populations\n",
        "    \"\"\"\n",
        "    remove_index = []\n",
        "    for i in range(0, len(random_pop)):\n",
        "        flag = 0\n",
        "        for j in range(0, len(cluster_centers)):\n",
        "            if(isEqual(random_pop[i], cluster_centers[j])):\n",
        "                flag = 1\n",
        "                break\n",
        "        if(flag==1):\n",
        "            remove_index.append(i)\n",
        "\n",
        "    remove_index.sort(reverse = True)\n",
        "    for i in remove_index:\n",
        "        del random_pop[i]\n",
        "    \n",
        "    #------------------------------------------------------------\n",
        "\n",
        "    # find the fitness of the non-cluter center individual\n",
        "    non_cluster_pop_fit, non_cluster_pop_acc = [], []\n",
        "\n",
        "    for i in range(0, len(random_pop)):\n",
        "        ind_fit_acc = getFitness(random_pop[i])\n",
        "        non_cluster_pop_fit.append(ind_fit_acc[0])\n",
        "        non_cluster_pop_acc.append(ind_fit_acc[1])\n",
        "\n",
        "    # find the fitness of the cluster individual\n",
        "    cluster_pop_fit, cluster_pop_acc = [], []\n",
        "    for i in range(0, len(cluster_centers)):\n",
        "        ind_fit_acc = getFitness(cluster_centers[i])\n",
        "        cluster_pop_fit.append(ind_fit_acc[0])\n",
        "        cluster_pop_acc.append(ind_fit_acc[1])\n",
        "\n",
        "    #-----------------------------------------------------------\n",
        "    # Assign the individual to a particular cluster\n",
        "    ind_belongs_to_cluter = []\n",
        "    for i in range(0, len(random_pop)):\n",
        "        ind_fit = non_cluster_pop_fit[i]  # fitness of the current individual\n",
        "        ind_acc = non_cluster_pop_acc[i]  # accuracy of the current individual\n",
        "\n",
        "        similar_list  = []\n",
        "        for j in range(0, no_cluster_center):\n",
        "            cluster_fit = cluster_pop_fit[j]  # fitness of the cluster center\n",
        "            cluster_acc = cluster_pop_acc[j] # accuracy of the cluster center \n",
        "            \n",
        "            # compute similarity between the cluster center and the current individual\n",
        "            similarity = cal_similarity(random_pop[i], cluster_centers[j], ind_acc, cluster_acc)\n",
        "            similar_list.append(similarity)\n",
        "        # get the cluster no which has the highest similarity\n",
        "        ind_belongs_to_cluter.append(similar_list.index(max(similar_list)))\n",
        "    #-----------------------------------------------------------    \n",
        "    #print(ind_belongs_to_cluter)\n",
        "    \"\"\"\n",
        "    Now we will be taking only one individual out the cluster \n",
        "    to do so there may be some cluster which has only one point\n",
        "    then at that case don't compute the part-2 rather than that\n",
        "    directly add that cluster center into the final ouput population.\n",
        "    \"\"\"\n",
        "    li1 = set(ind_belongs_to_cluter)\n",
        "    li2 = [i for i in range(population_size)]\n",
        "    direct_add = list(set(li1) - set(li2)) + list(set(li2) - set(li1))\n",
        "    direct_add.sort(reverse=True)\n",
        "    # directly add then into final population from cluster center\n",
        "    for d in direct_add:\n",
        "        population.append(cluster_centers[d])\n",
        "        population_fit.append(cluster_pop_fit[d])\n",
        "        population_acc.append(cluster_pop_acc[d])\n",
        "    #----------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "    #-----------------------------------------------------------\n",
        "    for i in range(0, len(cluster_centers)):\n",
        "        status = False\n",
        "        # if the cluster has only the cluster center then don't comput the nested loop\n",
        "        for temp in direct_add:\n",
        "            if(temp==i):\n",
        "                status = True\n",
        "                break\n",
        "        if(status):\n",
        "            continue\n",
        "        cluster_fit = cluster_pop_fit[i]\n",
        "\n",
        "        # go for the individual belongs to this cluster\n",
        "        ind_index = []\n",
        "        same_cluster_ind_fit = []\n",
        "        for j in range(0, len(ind_belongs_to_cluter)):\n",
        "            if(ind_belongs_to_cluter[j]==i):\n",
        "                ind_index.append(j)\n",
        "                #store this individuals fitness value\n",
        "                same_cluster_ind_fit.append(non_cluster_pop_fit[j])\n",
        "        # compute the maximum fitness\n",
        "        if(max(same_cluster_ind_fit)>cluster_fit):\n",
        "            # put the heighest fit individual to the population cluster\n",
        "            put_index = ind_index[same_cluster_ind_fit.index(max(same_cluster_ind_fit))]\n",
        "            population.append(random_pop[put_index])\n",
        "            population_fit.append(non_cluster_pop_fit[put_index])\n",
        "            population_acc.append(non_cluster_pop_acc[put_index])\n",
        "        else:\n",
        "            # put the cluster center into the population\n",
        "            population.append(cluster_centers[i])\n",
        "            population_fit.append(cluster_pop_fit[i])\n",
        "            population_acc.append(cluster_pop_acc[i])\n",
        "    #-------------------------------------------------------------------\n",
        "    return population, population_fit, population_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVLCyF4Qk4ME"
      },
      "source": [
        "# SA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ssJeCgs-a4Bi"
      },
      "outputs": [],
      "source": [
        "#================================ From Indivisuals to selected feature vector===============================\n",
        "def get_features(ind):\n",
        "    \"\"\"\n",
        "    Input: takes an individual of shape (no_of_features, )\n",
        "    Output: retuns name of the selecetd features.\n",
        "    Functionality: converts and indiviual form to an selected feature vector form.\n",
        "    \"\"\"\n",
        "    # store all the feature vectors of the given dataset\n",
        "    all_features = list(x_train.columns)\n",
        "    features_names = []\n",
        "    for i in range(0, len(ind)):\n",
        "        if(ind[i]==1):\n",
        "            features_names.append(all_features[i])\n",
        "    return features_names\n",
        "#============================================================================================\n",
        "\n",
        "#=============================  Fitness Function   ==========================================\n",
        "def getFitness(individual):\n",
        "    \"\"\"\n",
        "    Input: takes an individual of shape (no_of_features, )\n",
        "    Output: retuns a tuple of (fitnesss_value, accuracy)\n",
        "    Functionality: computes the fitness value of the given individual.\n",
        "    \"\"\"\n",
        "    global gamma, y, mi_selected_features\n",
        "    sum_mi = 0\n",
        "\n",
        "    # calculate the total no of features in the dataset.\n",
        "    total_no_features = int(x_train.shape[1])\n",
        "\n",
        "    # get the name of selected feature vectors from individual \n",
        "    selected_features = get_features(individual)\n",
        "\n",
        "    # calculate the no of selected feature vector\n",
        "    selected_no_fectures = len(selected_features)\n",
        "\n",
        "    # If the no of selected feature vector is 0 then return (0, 0)\n",
        "    if(selected_no_fectures==0):\n",
        "        return (0, 0)\n",
        "\n",
        "    # 1st objective function\n",
        "    _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "    x_train_temp = x_train[selected_features]\n",
        "    x_test_temp = x_test[selected_features]\n",
        "    _classifier.fit(x_train_temp, y_train)\n",
        "    predictions = _classifier.predict(x_test_temp)\n",
        "    accuracy = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "    \"\"\"\n",
        "    3rd objective:\n",
        "    compute the mutual information between the selected feature vector and class vector\n",
        "    \"\"\"\n",
        "    for i in range(0, len(individual)):\n",
        "        if(individual[i]==1):\n",
        "            sum_mi += mi_selected_features[i]\n",
        "    sum_mi = sum_mi/selected_no_fectures\n",
        "    obj_3rd = sum_mi\n",
        "\n",
        "    # calculate the final multiobjective fitness function\n",
        "    my_fitness = alpha*accuracy + (1-alpha)*(gamma * ((total_no_features - selected_no_fectures)/total_no_features) + (1-gamma)*obj_3rd)\n",
        "    \n",
        "    return (my_fitness, accuracy)\n",
        "#============================================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NtXZ4HzYSn-G"
      },
      "outputs": [],
      "source": [
        "class Simulated_Annealing(object):\n",
        "    \n",
        "    def __init__(self, max_iter = 100):\n",
        "        \"\"\"\n",
        "        Intialization of the Hyperparameters of SA.\n",
        "        \"\"\"\n",
        "        self.max_iter = max_iter\n",
        "        self.total_features = int(x_train.shape[1])\n",
        "        # create a dataframe\n",
        "        self.logfile = pd.DataFrame(columns=['fitness','accuracy', 'no_of_features'])\n",
        "\n",
        "    def isValidInd(self, individual):\n",
        "        \"\"\"\n",
        "        Input: Individual of shape (no_of_selected_feature, )\n",
        "        Output: binary i.e. True or False\n",
        "              False: If we have the Invalid Individual\n",
        "              True: If we have the alid Individual\n",
        "        Functionality:  checks whether a individual is valid or not.\n",
        "                      validity means if we have the 0 in all gene positions \n",
        "                      of an individual then that individual is not valid.\n",
        "        \"\"\"\n",
        "        if((set(individual))=={0}):\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "    def find_new_individual(self, individual):\n",
        "        \"\"\"\n",
        "        Input:  Current Individual of shape (no_of_selected_feature, )\n",
        "        Output: New state i.e. Next Individual of shape (no_of_selected_feature, )\n",
        "        Functionality: generates a new solution/individual from the current solution/individual\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        changes: instead of middle point now it's a random point in between \n",
        "        int(0.30*total_features) and celling(0.70total_features)\n",
        "        \"\"\"\n",
        "        position = []\n",
        "        #methods = \"middle\"\n",
        "        methods = \"30-40\"\n",
        "\n",
        "        if(methods == \"30-40\"):\n",
        "            # methods = \"30-40\"\n",
        "            temp_1 = int(self.total_features*0.30)\n",
        "            temp_2 = int(self.total_features*0.70)\n",
        "            end_point = random.randint(temp_1, temp_2)\n",
        "\n",
        "            position.append(random.randint(0, end_point))\n",
        "            position.append(random.randint(end_point+1, self.total_features-1))\n",
        "        else:\n",
        "            # methods = \"middle\"\n",
        "            position.append(random.randint(0, math.floor(self.total_features/2)))\n",
        "            position.append(random.randint(math.floor(self.total_features/2)+1, self.total_features-1))\n",
        "        \n",
        "        for i in range(0, 2):\n",
        "            if individual[position[i]] == 1:\n",
        "                individual[position[i]] = 0\n",
        "            else:\n",
        "                individual[position[i]] = 1\n",
        "        \n",
        "        # check wheather the new state/individual is valid or not\n",
        "        if(self.isValidInd(individual)):\n",
        "            return individual\n",
        "        else:\n",
        "            # if the individual is not valid then generate the new state or new indivisual\n",
        "            return get_individual()\n",
        "\n",
        "    def result(self):\n",
        "        \"\"\"\n",
        "        show the result after the convergence.\n",
        "        \"\"\"\n",
        "        # calculate the no of selected features in optimal individual\n",
        "        no_of_selected_features = 0\n",
        "        for i in range(0, len(self.best_individual)):\n",
        "            if(self.best_individual[i] == 1):\n",
        "                no_of_selected_features += 1\n",
        "        \n",
        "        # get the selected feature vectors name\n",
        "        selected_features = get_features(self.best_individual)\n",
        "        _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "        x_train_temp = x_train[selected_features]\n",
        "        x_test_temp = x_test[selected_features]\n",
        "        _classifier.fit(x_train_temp, y_train)\n",
        "        predictions = _classifier.predict(x_test_temp)\n",
        "        accuracy = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "        return self.best_individual, self.best_fitness, accuracy, no_of_selected_features, self.logfile\n",
        "\n",
        "    def simulated_annealing(self, initial_indivsual):\n",
        "        \"\"\"\n",
        "        Input: initial_indivsual, intitial individual of shape(no_of_features, )\n",
        "        \"\"\"\n",
        "        sa_accuracy, fitness, iter_values, all_ind = [], [], [], []\n",
        "        my_iter = 0\n",
        "        \n",
        "        # get the initial fitness\n",
        "        initial_fitness, intial_acc = getFitness(initial_indivsual)\n",
        "\n",
        "        current_individual, current_fitness, current_acc = initial_indivsual, initial_fitness, intial_acc\n",
        "        self.initial_indivsual = current_individual\n",
        "        \n",
        "        run_wise_fitness, run_wise_accuracy, run_wise_no_of_features = [], [], []\n",
        "\n",
        "        \"\"\"\n",
        "        initial temp is equal to 2*N\n",
        "        where N is the total no of features\n",
        "        \"\"\"\n",
        "        temp = 2*self.total_features\n",
        "\n",
        "        while my_iter < self.max_iter:\n",
        "            next_individual = self.find_new_individual(current_individual)\n",
        "            next_fitness, next_accuracy = getFitness(next_individual)\n",
        "            if current_fitness > next_fitness:\n",
        "                # i.e. bad moves then accept new individual with some probability value\n",
        "                e_x = (my_iter/temp)*((current_fitness-next_fitness)/current_fitness)\n",
        "                probabilty = math.exp(-e_x)\n",
        "                random_value = random.random()\n",
        "                if random_value <= probabilty: # then accept that bad move\n",
        "                    current_individual = next_individual\n",
        "                    current_fitness = next_fitness\n",
        "                    current_acc = next_accuracy\n",
        "            else:\n",
        "                # directly accepts the new state\n",
        "                current_individual = next_individual\n",
        "                current_fitness = next_fitness\n",
        "                current_acc = next_accuracy\n",
        "            # store the fitness, accuracy and no_of_features in a dataframe and then at the end store as a csv file\n",
        "            run_wise_fitness.append(current_fitness)\n",
        "            run_wise_accuracy.append(current_acc)\n",
        "            run_wise_no_of_features.append(len(get_features(current_individual)))\n",
        "            \n",
        "\n",
        "            all_ind.append(np.array(current_individual))\n",
        "            fitness.append(current_fitness)\n",
        "            my_iter += 1\n",
        "            temp = 0.93*temp # 0.93 is the another hyperparameter i.e. it is a cooling factor\n",
        "        self.best_individual = list(all_ind[fitness.index(max(fitness))])\n",
        "        self.best_fitness = max(fitness)\n",
        "        self.logfile['accuracy'] = run_wise_accuracy\n",
        "        self.logfile['fitness'] = run_wise_fitness\n",
        "        self.logfile['no_of_features'] = run_wise_no_of_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "C7IPQJfUNHMW"
      },
      "outputs": [],
      "source": [
        "def isEqual(ind1, ind2):\n",
        "    \"\"\"\n",
        "    Input: two lists (Indivisual_1, Indivisual_2)\n",
        "    Output: boolen value i.e. True or False\n",
        "    Functionality:  If two individual ind1 and ind2 are same then \n",
        "                    output is True.\n",
        "                    otherwise False\n",
        "    \"\"\"\n",
        "    status = False\n",
        "    for k in range(0, len(ind1)):\n",
        "        if(ind1[k] == ind2[k]):\n",
        "            status = True\n",
        "            continue\n",
        "        else:\n",
        "            status = False\n",
        "            break\n",
        "    return status\n",
        "\n",
        "def check_overlapping(pop, pop_fitness, pop_acc):\n",
        "    \"\"\"\n",
        "    Input: population, population_fitness, population_accuracy\n",
        "    Output: population, population_fitness, population_accuracy\n",
        "    Functionality:  Takes an population and checks if there are\n",
        "                    multiple copies of a individual then remove\n",
        "                    all these copies.\n",
        "    \"\"\"\n",
        "    enable_output = False # to show the results\n",
        "    pop_copy = pop.copy()\n",
        "    pop_fitness_copy = pop_fitness.copy()\n",
        "    pop_acc_copy = pop_acc.copy()\n",
        "    remove_index = []\n",
        "    for i in range(0, len(pop)):\n",
        "        counter = i\n",
        "        for j in pop[i+1:]:\n",
        "            counter += 1\n",
        "            \"\"\"\n",
        "            If two individuals are same then store these same\n",
        "            indiviual's index number for delete.\n",
        "            \"\"\"\n",
        "            if(isEqual(pop[i], j)):\n",
        "                remove_index.append(counter)\n",
        "    remove_index = list(set(remove_index))\n",
        "    remove_index.sort(reverse = True)\n",
        "    \n",
        "    # delete the copy individuals from populations\n",
        "    for i in remove_index:\n",
        "        del pop_copy[i]\n",
        "        del pop_fitness_copy[i]\n",
        "        del pop_acc_copy[i]\n",
        "    \n",
        "    if(enable_output):\n",
        "        if(len(pop_copy) == len(pop)):\n",
        "            print(\"\\nNo overlapping has been occured!!\")\n",
        "            print(\"Current population size: \", len(pop_copy))\n",
        "        else:\n",
        "            print(\"Overlapping occured. Current population size: \", len(pop_copy))\n",
        "    \n",
        "    return pop_copy, pop_fitness_copy, pop_acc_copy\n",
        "\n",
        "def get_individual():\n",
        "    \"\"\"\n",
        "    Input: \n",
        "    Output: individual\n",
        "    Functionality:  generate an individual.\n",
        "                    genes are randomly generated.\n",
        "    \"\"\"\n",
        "    individual = []\n",
        "    for i in range(0, x_train.shape[1]):\n",
        "        gene = random.randint(0, 1)\n",
        "        individual.append(gene)\n",
        "    return individual\n",
        "\n",
        "def get_population(population_size):\n",
        "    global sa_all_population_run_wise\n",
        "    \"\"\"\n",
        "    Input: an integer, population_size\n",
        "    Output: SA_generated_population, SA_generated_population_fitness,\n",
        "            SA_generated_population_accuarcy \n",
        "    Functionality:  generate population with twice of the actual population size.\n",
        "                    then remove the repetating indivisuals.\n",
        "                    then choose the best individuals out of the current population.\n",
        "    \"\"\"\n",
        "    population, population_fitness, population_accuracy  = [], [], []\n",
        "    while(len(population)<=population_size):\n",
        "        cbpi_pop, cbpi_pop_fit, cbi_pop_acc = CBPI(population_size)\n",
        "        # First generate population by SA\n",
        "        sa_all_population_run_wise = [] # store the run_wise data\n",
        "        # store the intial population also, so that we can run the same for the GA also\n",
        "        with open('cbpi_pop.txt', 'w') as f:\n",
        "            for item in cbpi_pop:\n",
        "                f.write(\"%s\\n\" % item)\n",
        "\n",
        "        for i in range(0, population_size):\n",
        "            #ind = get_individual() # get the randomly generated individual\n",
        "            ind = cbpi_pop[i]#cbpi_population_sa_ga[i]#\n",
        "            SA = Simulated_Annealing() # get the SA object\n",
        "            SA.simulated_annealing(ind) # pass the randomly genrated individual to the SA\n",
        "            best_individual, fitness, acc, no_of_selected_features, sa_logfile = SA.result() # get the SA generated results\n",
        "            sa_all_population_run_wise.append(sa_logfile)\n",
        "            population.append(best_individual) # store the SA generated output indivisual \n",
        "            population_fitness.append(fitness) # store the SA generated fitness value of the final individual \n",
        "            population_accuracy.append(acc) # store the SA generated accuarcy value of the final individual \n",
        "      \n",
        "        # check the repetation is there or not\n",
        "        population, population_fitness, population_accuracy = check_overlapping(population, population_fitness, population_accuracy)\n",
        "        #break\n",
        "    \n",
        "        \"\"\"\n",
        "        If the current population size is equal to the desired population size then return, else\n",
        "        choose the best indivisuals out the of the current population.\n",
        "        \"\"\"\n",
        "\n",
        "        if(len(population)==population_size):\n",
        "            return population, population_fitness, population_accuracy\n",
        "        else:\n",
        "            \"\"\"\n",
        "            Now choose the best indivisuals out the of the current population.\n",
        "            Sort by accuracy first then sort by fitness.\n",
        "            To implement this use dataframe.\n",
        "            \"\"\"\n",
        "            sa_population, sa_fitness, sa_acc = [], [], []\n",
        "            \n",
        "            #store in a dataframe format\n",
        "            sa_df = create_dataframe(population, population_accuracy, population_fitness)\n",
        "\n",
        "            # sort the dataframe based on first Accuarcy then based on Fitness in decending order.\n",
        "            sa_df.sort_values([\"Accuracy\", \"Fitness\"], axis=0, ascending=False, inplace=True)\n",
        "            \n",
        "            # store all of the columns i.e. Individual, Accuracy, Fitness\n",
        "            sa_population_all = list(sa_df['Individual'])\n",
        "            sa_acc_all = list(sa_df['Accuracy'])\n",
        "            sa_fitness_all = list(sa_df['Fitness'])\n",
        "\n",
        "            # create the population containg best individuals\n",
        "            for i in range(0, population_size):\n",
        "                sa_population.append(list(sa_population_all[i]))\n",
        "                sa_fitness.append(sa_fitness_all[i])\n",
        "                sa_acc.append(sa_acc_all[i])\n",
        "            \n",
        "            return sa_population, sa_fitness, sa_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wMHjgTrj-Fxa"
      },
      "outputs": [],
      "source": [
        "def create_dataframe(ind, acc, fit):\n",
        "    \"\"\"\n",
        "    Input: individual, accuarcy and fitness\n",
        "    output: return a dataframe\n",
        "    \"\"\"\n",
        "    data = {'Individual':['123'], 'Accuracy':['123'], 'Fitness': ['123']}\n",
        "    df = pd.DataFrame(data) # Create DataFrame\n",
        "    for i in range(0, len(ind)):\n",
        "        df.loc[len(df.index)] = [ind[i], acc[i], fit[i]]\n",
        "    df = df.drop(0) # Now delete the fist row\n",
        "    return df\n",
        "\n",
        "def concatenate_dataframe(df1, df2):\n",
        "    \"\"\"\n",
        "    Input: two dataframes\n",
        "    Output: concatenates two input dataframes\n",
        "    \"\"\"\n",
        "    frames = [df1, df2]\n",
        "    concatenated_dataframe = pd.concat(frames)\n",
        "    return concatenated_dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTnKK2BWoxwl"
      },
      "source": [
        "# GA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9NKKuumfrONS"
      },
      "outputs": [],
      "source": [
        "#==============================================================================================\n",
        "class Solution():    \n",
        "    #structure of the solution \n",
        "    def __init__(self):\n",
        "        self.num_features = None\n",
        "        self.population_size = None\n",
        "        self.num_generations = None\n",
        "        self.best_individual = None\n",
        "        self.best_fitness = None\n",
        "        self.best_accuracy = None\n",
        "        self.final_population = None\n",
        "        self.final_fitness = None\n",
        "        self.final_accuracy = None\n",
        "        self.history = None\n",
        "#==============================================================================================\n",
        "class Genetic_Algorithm(object):\n",
        "\n",
        "    def __init__(self, max_iter):\n",
        "        global num_generations\n",
        "        self.population_size = len(population)\n",
        "        self.save_conv_graph = False\n",
        "        pop = np.ones((len(population), len(population[0])))\n",
        "        for i in range(0, pop.shape[0]):\n",
        "            pop[i] = np.array(population[i])\n",
        "        self.population = pop\n",
        "        self.fitness = np.array(sa_fitness)\n",
        "        self.num_features = x_train.shape[1]\n",
        "        self.accuracy = np.array(sa_accuracy)\n",
        "        self.Leader_fitness = float(\"-inf\")\n",
        "        self.Leader_accuracy = float(\"-inf\")\n",
        "        self.history = []\n",
        "        self.cur_iter = 0\n",
        "        self.num_generations = num_generations\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "        self.solution = None\n",
        "        self.verbose = False\n",
        "\n",
        "        self.prob_cross = 0.7\n",
        "        self.prob_mut = 0.3\n",
        "        self.cross_limit = 10\n",
        "        self.prob_cross_max = 0.7\n",
        "        self.prob_cross_min = 0.6\n",
        "        self.prob_mut_max = 0.4\n",
        "        self.prob_mut_min = 0.3\n",
        "        self.logfile = pd.DataFrame(columns=['fitness','accuracy', 'no_of_features'])\n",
        "\n",
        "    def sort_agents(self, agents, fitness, accuracy):\n",
        "        # sort the agents according to fitness\n",
        "        idx = np.argsort(-fitness)\n",
        "        sorted_agents = agents[idx].copy()\n",
        "        sorted_fitness = fitness[idx].copy()\n",
        "        sorted_accuracy = accuracy[idx].copy()\n",
        "        return sorted_agents, sorted_fitness, sorted_accuracy\n",
        "    \n",
        "    def get_fitness(self, pop):\n",
        "        \"\"\"\n",
        "        Input: population, 2D array\n",
        "        Output: an 1D array\n",
        "        Functionality: calculate the fitness of the population.\n",
        "        \"\"\"\n",
        "        fitness, accuracy = [], []\n",
        "        for i in range(0, len(pop)):\n",
        "            ind_fitness = getFitness(pop[i])\n",
        "            fitness.append(ind_fitness[0])\n",
        "            accuracy.append(ind_fitness[1])\n",
        "        accuracy = np.array(accuracy)\n",
        "        return np.array(fitness), accuracy\n",
        "\n",
        "    def initialize(self):\n",
        "        # set the objective function\n",
        "        self.weight_acc = 0.9\n",
        "        self.population, self.fitness, self.accuracy = self.sort_agents(agents = self.population, fitness = self.fitness, accuracy = self.accuracy)\n",
        "        # save the best fittest individual and it's fitness value\n",
        "        self.Leader_agent, self.Leader_fitness = self.population[0], self.fitness[0]\n",
        "\n",
        "    def save_details(self):\n",
        "        # save some details of every generation\n",
        "        cur_obj = {\n",
        "            'population': self.population,\n",
        "            'fitness': self.fitness,\n",
        "            'accuracy': self.accuracy,\n",
        "        }\n",
        "        self.history.append(copy.deepcopy(cur_obj))\n",
        "\n",
        "    def display(self):\n",
        "        # display the current generation details\n",
        "        if self.verbose:\n",
        "            for i in range(0, len(self.population)):\n",
        "                print(\"agents = \", self.population[i], \" fitness = \", self.fitness[i], \" accuracy = \", self.accuracy[i])\n",
        "\n",
        "    def plot(self):\n",
        "        # plot the convergence graph\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        avg_fitness, avg_accuracy = [], []\n",
        "        for cur in self.history:\n",
        "            avg_fitness.append(np.mean(cur['fitness']))\n",
        "            avg_accuracy.append(np.mean(cur['accuracy']))\n",
        "\n",
        "        plt.plot(np.arange(len(avg_fitness)), avg_fitness,  color = 'r', label = 'fitness')\n",
        "        plt.plot(np.arange(len(avg_accuracy)), avg_accuracy,  color = 'g', label = 'accuracy')\n",
        "        plt.plot(np.arange(len(avg_accuracy)), self.max_fit_per_gen,  color = 'orange', label = 'max-fit')\n",
        "        plt.plot(np.arange(len(avg_accuracy)), self.max_acc_per_gen,  color = 'b', label = 'max-acc')\n",
        "        plt.xlabel('Number of Generations')\n",
        "        plt.ylabel('Average Fitness and Accuracy')\n",
        "        plt.title('Convergence Curve')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        return fig\n",
        "\n",
        "    def post_processing(self):\n",
        "        # post processing steps\n",
        "        fit_acc = self.get_fitness(self.population)\n",
        "        self.fitness = fit_acc[0]\n",
        "        self.accuracy = fit_acc[1]\n",
        "        self.population, self.fitness, self.accuracy = self.sort_agents(agents = self.population, fitness = self.fitness, accuracy = self.accuracy)\n",
        "        \n",
        "        if(self.fitness[0] > self.Leader_fitness):\n",
        "            self.Leader_fitness = self.fitness[0]\n",
        "            self.Leader_agent = self.population[0, :]\n",
        "            self.Leader_accuracy = self.accuracy[0]\n",
        "\n",
        "    def save_solution(self):\n",
        "        # create a solution object\n",
        "        self.solution = Solution()\n",
        "        self.solution.population_size = self.population_size\n",
        "        self.solution.num_generations = self.num_generations\n",
        "\n",
        "        # update attributes of solution\n",
        "        self.solution.best_individual = self.Leader_agent\n",
        "        self.solution.best_fitness = self.Leader_fitness\n",
        "        self.solution.best_accuracy = self.Leader_accuracy\n",
        "        self.solution.final_population = self.population\n",
        "        self.solution.final_fitness = self.fitness\n",
        "        self.solution.final_accuracy = self.accuracy\n",
        "\n",
        "    def crossover(self, parent_1, parent_2):\n",
        "        # perform crossover with crossover probability prob_cross\n",
        "        num_features = parent_1.shape[0]\n",
        "        child_1 = parent_1.copy()\n",
        "        child_2 = parent_2.copy()\n",
        "\n",
        "        for i in range(num_features):\n",
        "            if(np.random.rand() < self.prob_cross):\n",
        "                child_1[i] = parent_2[i]\n",
        "                child_2[i] = parent_1[i]\n",
        "\n",
        "        return child_1, child_2\n",
        "\n",
        "    def mutation(self, chromosome):\n",
        "        # perform mutation with mutation probability prob_mut\n",
        "        num_features = chromosome.shape[0]\n",
        "        mut_chromosome = chromosome.copy()\n",
        "\n",
        "        for i in range(num_features):\n",
        "            if(np.random.rand() < self.prob_mut):\n",
        "                mut_chromosome[i] = 1-mut_chromosome[i]\n",
        "        \n",
        "        return mut_chromosome\n",
        "\n",
        "    def roulette_wheel(self, fitness):\n",
        "        # perform roulette wheel selection\n",
        "        maximum = sum([f for f in fitness])\n",
        "        selection_probs = [f/maximum for f in fitness]\n",
        "        return np.random.choice(len(fitness), p=selection_probs)\n",
        "\n",
        "    def cross_mut(self):\n",
        "        # perform crossover, mutation and replacement\n",
        "        count = 0\n",
        "        #print('Crossover-Mutation phase starting....')\n",
        "\n",
        "        while(count < self.cross_limit):\n",
        "            #print('\\nCrossover no. {}'.format(count+1))\n",
        "            id_1 = self.roulette_wheel(self.fitness)\n",
        "            id_2 = self.roulette_wheel(self.fitness)\n",
        "\n",
        "            if(id_1 != id_2):\n",
        "                child_1, child_2 = self.crossover(self.population[id_1, :], self.population[id_2, :])\n",
        "                child_1 = self.mutation(child_1)\n",
        "                child_2 = self.mutation(child_2)\n",
        "\n",
        "                child = np.array([child_1, child_2])\n",
        "                child_fit_acc = self.get_fitness(child)\n",
        "                child_fitness = child_fit_acc[0]\n",
        "                chile_acc = child_fit_acc[1]\n",
        "                child, child_fitness, chile_acc = self.sort_agents(child, child_fitness, chile_acc)\n",
        "\n",
        "                for i in range(2):\n",
        "                    for j in reversed(range(self.population_size)):\n",
        "                        if(child_fitness[i] > self.fitness[j]):\n",
        "                            #print('child {} replaced with chromosome having id {}'.format(i+1, j+1))\n",
        "                            self.population[j, :] = child[i]\n",
        "                            self.fitness[j] = child_fitness[i]\n",
        "                            self.accuracy[j] = chile_acc[i]\n",
        "                            break\n",
        "                \n",
        "                count+= 1\n",
        "\n",
        "            else:\n",
        "                pass\n",
        "                \"\"\"\n",
        "                print('Crossover failed....')\n",
        "                print('Restarting crossover....\\n')\n",
        "                \"\"\"\n",
        "    \n",
        "    def get_results(self):\n",
        "        # sort the dataframe based on first Accuarcy then based on Fitness in decending order.\n",
        "        self.ga_df.sort_values([\"Accuracy\", \"Fitness\"], axis=0, ascending=False, inplace=True)\n",
        "        \n",
        "        # store all of the columns i.e. Individual, Accuracy, Fitness\n",
        "        best_ind = list(self.ga_df['Individual'])[0]\n",
        "        best_ind_acc = list(self.ga_df['Accuracy'])[0]\n",
        "        best_ind_fit = list(self.ga_df['Fitness'])[0]\n",
        "\n",
        "        # caculate the no of features selected in best individual\n",
        "        count = 0\n",
        "        for i in best_ind:\n",
        "            if(i==1):\n",
        "                count += 1\n",
        "\n",
        "        return best_ind, best_ind_acc, best_ind_fit, count\n",
        "\n",
        "    def run(self):\n",
        "        global ga_run_wise_accuracy, ga_run_wise_fitness, ga_run_wise_no_of_features\n",
        "        self.max_fit_per_gen, self.max_acc_per_gen = [], []\n",
        "        self.initialize()   # initialize the algorithm\n",
        "        self.save_details() # save the initial details\n",
        "        self.max_fit_per_gen.append(np.max(self.fitness))\n",
        "        self.max_acc_per_gen.append(np.max(self.accuracy))\n",
        "\n",
        "        # create the dataframe to store the population and it's fitness value and the accuracy\n",
        "        self.ga_df = create_dataframe(self.population, self.accuracy, self.fitness)\n",
        "        ga_run_wise_accuracy, ga_run_wise_fitness, ga_run_wise_no_of_features = [], [], []\n",
        "        for generation in range(self.num_generations):    # while the end criterion is not met\n",
        "            ga_run_wise_accuracy.append(self.accuracy)\n",
        "            ga_run_wise_fitness.append(self.fitness)\n",
        "            for ind in self.population:\n",
        "                ga_run_wise_no_of_features.append(len(get_features(ind)))\n",
        "            #print(self.fitness)\n",
        "            #print(self.accuracy)\n",
        "\n",
        "            self.cross_mut()\n",
        "\n",
        "            self.cur_iter+= 1\n",
        "\n",
        "            # store all the population and fitness and the accuracy in the dataframe format\n",
        "            # add current individual, accuracy and fitness in the dataframe\n",
        "            self.ga_df_next = create_dataframe(self.population, self.accuracy, self.fitness)\n",
        "            self.ga_df = concatenate_dataframe(self.ga_df_next, self.ga_df)\n",
        "\n",
        "            \"\"\"\n",
        "            # Adopt the crossover and mutation probability\n",
        "            f_dash is the fitness of one of the parent\n",
        "            f_avg is the average fitness of the population.\n",
        "            f is the fitness of the one for mutation. i.e. kind of a thershold value.\n",
        "            \"\"\"\n",
        "\n",
        "            if(cross_mut == \"adaptive\"):\n",
        "                f_avg = np.mean(self.fitness)\n",
        "                # for crossover\n",
        "                f_dash = self.fitness[random.randint(0, int(self.fitness.shape[0]/2))]\n",
        "                if(f_dash > f_avg):\n",
        "                    self.prob_cross = self.prob_cross_max - generation*((self.prob_cross_max - self.prob_cross_min)/self.num_generations)\n",
        "                else:\n",
        "                    self.prob_cross = self.prob_cross_max\n",
        "            \n",
        "                # for mutation\n",
        "                f = 0.80\n",
        "                if(f>f_avg):\n",
        "                    self.prob_mut = self.prob_mut_min + generation*((self.prob_mut_max - self.prob_mut_min)/self.num_generations)\n",
        "                else:\n",
        "                    self.prob_mut = self.prob_mut_min\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "            #----------------------------------------------\n",
        "\n",
        "            self.post_processing()          # do the post processing steps\n",
        "            self.display()                  # display the details of 1 iteration\n",
        "            self.save_details()             # save the details\n",
        "            self.max_fit_per_gen.append(np.max(self.fitness))\n",
        "            self.max_acc_per_gen.append(np.max(self.accuracy))\n",
        "\n",
        "        fit_acc = getFitness(self.Leader_agent)\n",
        "        self.Leader_fitness = fit_acc[0]\n",
        "        self.Leader_accuracy = fit_acc[1]\n",
        "\n",
        "        self.save_solution()\n",
        "\n",
        "        if(self.save_conv_graph):\n",
        "            fig = self.plot()\n",
        "            fig.savefig('convergence_curve_genetic_algo.jpg')\n",
        "\n",
        "        #print('\\n-------------  Leader Agent  ---------------')\n",
        "        #print('Fitness: {}'.format(self.Leader_fitness))\n",
        "        #print('Number of Features: {}'.format(int(np.sum(self.Leader_agent))))\n",
        "        #print('----------------------------------------\\n')\n",
        "        \n",
        "        return self.save_solution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3E8F7FlO4acD"
      },
      "outputs": [],
      "source": [
        "def get_data(file_name):\n",
        "    global mi_selected_features, dichotomas, sort_features_list, percentage\n",
        "    \"\"\"\n",
        "    Input: file name\n",
        "    Output: x_train, x_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_name, header = None)\n",
        "        tot_features = len(df.columns)-1\n",
        "        total_features = tot_features\n",
        "        x, y = df[df.columns[:tot_features]], df[df.columns[-1]]\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y)\n",
        "        _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "        _classifier.fit(x_train, y_train)\n",
        "        predictions = _classifier.predict(x_test)\n",
        "        total_acc = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "    except:\n",
        "        df = pd.read_csv(file_name)\n",
        "        tot_features = len(df.columns)-1\n",
        "        total_features = tot_features\n",
        "        x, y = df[df.columns[:tot_features]], df[df.columns[-1]]\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y)\n",
        "        _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "        _classifier.fit(x_train, y_train)\n",
        "        predictions = _classifier.predict(x_test)\n",
        "        total_acc = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "    print(\"Total features: \",total_features)\n",
        "    print(\"Accuracy, taking all features: \", total_acc*100)\n",
        "\n",
        "    # if total no of features less than 90% then don't need to drop features\n",
        "    if(dropping_way == 'static'):\n",
        "        # drop 25 % of the data directly\n",
        "        #percentage = 0.995\n",
        "        x_train, mi_selected_features = hybrid(x_train, y_train, percentage)\n",
        "        fecture_vectors = list(x_train.columns)\n",
        "        x_test = x_test[fecture_vectors]\n",
        "        return x_train, x_test, y_train, y_test\n",
        "    else:\n",
        "        if(total_features<10):\n",
        "            return x_train, x_test, y_train, y_test\n",
        "        elif(total_features<20):\n",
        "            # if no of features less than 20 then do only one time 25% features dropping\n",
        "            # feature dropping\n",
        "            percentage = 0.25\n",
        "            x_train, mi_selected_features = hybrid(x_train, y_train, percentage)\n",
        "            fecture_vectors = list(x_train.columns)\n",
        "            x_test = x_test[fecture_vectors]\n",
        "            return x_train, x_test, y_train, y_test\n",
        "        else:\n",
        "            if(dichotomas):\n",
        "                run_time = 1\n",
        "                while(True):\n",
        "                    if(x_train.shape[1]<20):\n",
        "                        # don't revome any more features\n",
        "                        break\n",
        "                    # drop25\n",
        "                    percentage25 = 0.25\n",
        "                    if(run_time==1):\n",
        "                        x_train25, mi_selected_features25 = hybrid(x_train, y_train, percentage25)\n",
        "                        fecture_vectors = list(x_train25.columns)\n",
        "                        x_test25 = x_test[fecture_vectors]\n",
        "\n",
        "                    else:\n",
        "                        x_train25, mi_selected_features25 = dropping(x_train, y_train, percentage25)\n",
        "                        fecture_vectors = list(x_train25.columns)\n",
        "                        x_test25 = x_test[fecture_vectors]\n",
        "                    \n",
        "                    run_time += 1\n",
        "\n",
        "                    _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "                    _classifier.fit(x_train25, y_train)\n",
        "                    predictions = _classifier.predict(x_test25)\n",
        "                    acc25 = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "              \n",
        "                    # drop50\n",
        "                    percentage50 = 0.50\n",
        "                    x_train50, mi_selected_features50 = dropping(x_train, y_train, percentage50)\n",
        "                    \n",
        "                    fecture_vectors = list(x_train50.columns)\n",
        "                    x_test50 = x_test[fecture_vectors]\n",
        "\n",
        "                    _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "                    _classifier.fit(x_train50, y_train)\n",
        "                    predictions = _classifier.predict(x_test50)\n",
        "                    acc50 = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "                    # drop50\n",
        "                    percentage75 = 0.75\n",
        "                    x_train75, mi_selected_features75 = dropping(x_train, y_train, percentage75)\n",
        "                    fecture_vectors = list(x_train75.columns)\n",
        "                    x_test75 = x_test[fecture_vectors]\n",
        "\n",
        "                    _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "                    _classifier.fit(x_train75, y_train)\n",
        "                    predictions = _classifier.predict(x_test75)\n",
        "                    acc75 = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "                    ##\n",
        "                    print(\"Dropping: \", total_acc, acc25, acc50, acc75)\n",
        "                    if(acc50 >= acc25):\n",
        "                        \n",
        "                        if(acc75 >= acc50):\n",
        "                            # drop 75% of the data\n",
        "                            x_train, x_test = x_train75, x_test75\n",
        "                            total_acc = acc75\n",
        "                            mi_selected_features = mi_selected_features75\n",
        "                            cutoff = int(math.floor(0.75*(x_train.shape[1])))\n",
        "                            sort_features_list = sort_features_list[0:cutoff]\n",
        "                            print(acc75)\n",
        "                          \n",
        "                          \n",
        "                        else:\n",
        "                            #drop 50% of the data\n",
        "                            x_train, x_test = x_train50, x_test50\n",
        "                            total_acc = acc50\n",
        "                            mi_selected_features = mi_selected_features50\n",
        "                            cutoff = int(math.floor(0.50*(x_train.shape[1])))\n",
        "                            sort_features_list = sort_features_list[0:cutoff]\n",
        "                            print(acc50)\n",
        "                  \n",
        "                    elif(acc25>=total_acc):\n",
        "                        #drop 25% of the data\n",
        "                        x_train, x_test = x_train25, x_test25\n",
        "                        total_acc = acc25\n",
        "                        mi_selected_features = mi_selected_features25\n",
        "                        cutoff = int(math.floor(0.25*(x_train.shape[1])))\n",
        "                        sort_features_list = sort_features_list[0:cutoff]\n",
        "                        print(acc25)\n",
        "                    else:\n",
        "                        break\n",
        "                    run_time = run_time +1\n",
        "                  \n",
        "                return x_train, x_test, y_train, y_test\n",
        "        \n",
        "            else:\n",
        "                percentage = 0.25\n",
        "                # drop the features until the convergence criteria satisfied\n",
        "                while(True):\n",
        "                    #print(percentage, total_acc)\n",
        "                    if(x_train.shape[1]<20):\n",
        "                        # don't revome any more features\n",
        "                        break\n",
        "                    x_train, mi_selected_features  = hybrid(x_train, y_train, percentage)\n",
        "                    fecture_vectors = list(x_train.columns)\n",
        "                    x_test = x_test[fecture_vectors]\n",
        "\n",
        "                    _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "                    _classifier.fit(x_train, y_train)\n",
        "                    predictions = _classifier.predict(x_test)\n",
        "                    total_acc_new = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "                    if(total_acc_new >= total_acc):\n",
        "                        #total_acc = total_acc_new\n",
        "                        x_train_to_save, x_test_to_save, y_train_to_save, y_test_to_save = x_train.copy(), x_test.copy(), y_train.copy(), y_test.copy()\n",
        "                        #percentage = percentage + 0.05\n",
        "                    else:\n",
        "                        break\n",
        "                return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GGAXGHffOzTU"
      },
      "outputs": [],
      "source": [
        "def display_results():\n",
        "    \"\"\"\n",
        "    display the results\n",
        "    \"\"\"\n",
        "    if(x_train.shape[1]>1000):\n",
        "        print(\"Fitness\", \"\\t\"*3, \"Accuracy\")\n",
        "        for i in range(0, len(population)):\n",
        "            print(sa_fitness[i], sa_accuracy[i])\n",
        "    else:\n",
        "        print(\"Individual\", \"\\t\"*5, \"Fitness\", \"\\t\"*3, \"Accuracy\")\n",
        "        for i in range(0, len(population)):\n",
        "            print(population[i], sa_fitness[i], sa_accuracy[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3au0q3ib7L6",
        "outputId": "9dad272e-2132-48d7-d458-07f7817c2f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Feature Selection/dataset/microarray/Leukaemiamattest.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/SRBCTGENE.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/dlbcl.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/braintumor.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/AMLGSE2191.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/MLLmattest.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/prostatemattest.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/lung.csv']\n",
            "/content/drive/MyDrive/Feature Selection/dataset/microarray/Leukaemiamattest.csv\n",
            "Total features:  5147\n",
            "Accuracy, taking all features:  93.33333333333333\n",
            "No of removed features:  5127\n",
            "No of selected features:  20\n",
            "Accuarcy with all the features:  93.33333333333333\n"
          ]
        }
      ],
      "source": [
        "files = glob.glob(\"/content/drive/MyDrive/Feature Selection/dataset/microarray/*.csv\")\n",
        "dropping_verbose = False\n",
        "dichotomas = True\n",
        "dropping_way = 'static'\n",
        "print(files)\n",
        "#Adaptive\n",
        "cross_mut = 'adaptive'\n",
        "\n",
        "data_type = \"microarray\"\n",
        "# Calculate the percentage of the\n",
        "no_of_wanted_features = 20\n",
        "percentage = (100 - (no_of_wanted_features/5147)*100)/100\n",
        "total_run = 10\n",
        "file_name = files[0]\n",
        "print(file_name)\n",
        "x_train, x_test, y_train, y_test = get_data(file_name)\n",
        "mi_selected_features = mutual_info_classif(x_train, y_train)\n",
        "# Train with all the features\n",
        "_classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "_classifier.fit(x_train, y_train)\n",
        "predictions = _classifier.predict(x_test)\n",
        "total_acc_new = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "print('Accuarcy with all the features: ', total_acc_new*100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# save this x_train and x_test and y_train and y_test\n",
        "x_train.to_csv('Leukaemiamattest_x_train.csv')\n",
        "x_test.to_csv('Leukaemiamattest_x_test.csv')\n",
        "y_train.to_csv('Leukaemiamattest_y_train.csv')\n",
        "y_test.to_csv('Leukaemiamattest_y_test.csv')\n",
        "# Load the saved data if you have\n",
        "x_train = pd.read_csv('Leukaemiamattest_x_train.csv')\n",
        "x_test = pd.read_csv('Leukaemiamattest_x_test.csv')\n",
        "y_train = pd.read_csv('Leukaemiamattest_y_train.csv')\n",
        "y_test = pd.read_csv('Leukaemiamattest_y_test.csv')\n",
        "x_train = x_train.drop(x_train.columns[0], axis=1)\n",
        "x_test = x_test.drop(x_test.columns[0], axis=1)\n",
        "y_train = y_train.drop(y_train.columns[0], axis=1)\n",
        "y_test = y_test.drop(y_test.columns[0], axis=1)\n",
        "'''"
      ],
      "metadata": {
        "id": "oZ6HG6UcjV_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SAGA"
      ],
      "metadata": {
        "id": "V8ffxAeuaa2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.80\n",
        "gamma = 0.70\n",
        "population_size = 30\n",
        "num_generations = 50\n",
        "\n",
        "# ======================.  SA    =========================\n",
        "print(\"population size: \", population_size)\n",
        "print('\\nSIMULATED ANNEALING\\n')\n",
        "population, sa_fitness, sa_accuracy = get_population(population_size)\n",
        "display_results()\n",
        "#######\n",
        "sa_pop_fit, sa_pop_acc, sa_pop_no_of_fe = [], [], []\n",
        "for i in range(0, 30):\n",
        "    df_draft = sa_all_population_run_wise[i]\n",
        "    sa_pop_fit.append(df_draft['fitness'])\n",
        "    sa_pop_acc.append(df_draft['accuracy'])\n",
        "    sa_pop_no_of_fe.append(df_draft['no_of_features'])\n",
        "# now do iter wise mean (column wise mean)\n",
        "sa_pop_fit, sa_pop_acc, sa_pop_no_of_fe = np.array(sa_pop_fit), np.array(sa_pop_acc), np.array(sa_pop_no_of_fe)\n",
        "\n",
        "mean_fit = np.max(sa_pop_fit, axis = 0)\n",
        "mean_acc = np.max(sa_pop_acc, axis = 0)\n",
        "mean_no_of_fe = np.max(sa_pop_no_of_fe, axis = 0)\n",
        "# set the gbest\n",
        "gbest_fit, gbest_acc = mean_fit[0], mean_acc[0]\n",
        "gbest_fitness, gbest_accuracy = [], []\n",
        "for i in range(0, len(mean_fit)):\n",
        "    if(mean_fit[i]>gbest_fit):\n",
        "        gbest_fit = mean_fit[i]\n",
        "        gbest_fitness.append(gbest_fit)\n",
        "    else:\n",
        "        gbest_fitness.append(gbest_fit)\n",
        "for i in range(0, len(mean_acc)):\n",
        "    if(mean_acc[i]>gbest_acc):\n",
        "        gbest_acc = mean_acc[i]\n",
        "        gbest_accuracy.append(gbest_acc)\n",
        "    else:\n",
        "        gbest_accuracy.append(gbest_acc)\n",
        "\n",
        "runs = np.arange(1, len(mean_fit[0:100])+1, 1)\n",
        "plt.plot(runs, gbest_fitness[0:100], color='orange', linewidth = 1.5)\n",
        "#plt.plot(runs, gbest_accuracy[0:100], label = 'accuracy', linewidth = 0.5)\n",
        "#plt.legend()\n",
        "plt.xlabel('Interations')\n",
        "plt.ylabel('Fitness')\n",
        "plt.title('Convergence of Fitness over Iterations using SA')\n",
        "plt.savefig('Leukaemiamattest_sa.pdf')\n",
        "plt.savefig('Leukaemiamattest_sa.png')\n",
        "plt.show()\n",
        "\n",
        "# =====================   GA.   ==========================\n",
        "algo = Genetic_Algorithm(max_iter = 30)\n",
        "solution = algo.run()\n",
        "best_ind, best_ind_acc, best_ind_fit, no_of_selected = algo.get_results()\n",
        "#fig = algo.plot()\n",
        "print(\"Best Individual: \", best_ind)\n",
        "print(\"Best individual accuracy: \", best_ind_acc)\n",
        "print(\"Best individual fitness: \", best_ind_fit)\n",
        "print(\"No of selected features: \", no_of_selected)\n",
        "ga_mean_fit, ga_mean_acc = [], []\n",
        "for i in range(0, len(ga_run_wise_accuracy)):\n",
        "    ga_mean_fit.append(np.max(ga_run_wise_fitness[i]))\n",
        "    ga_mean_acc.append(np.max(ga_run_wise_accuracy[i]))\n",
        "\n",
        "runs = np.arange(1, len(ga_mean_fit)+1, 1)\n",
        "plt.plot(runs, ga_mean_fit, color='orange', linewidth = 1.5)\n",
        "#plt.plot(runs, ga_mean_acc, label = 'accuracy', linewidth = 0.5)\n",
        "#plt.legend()\n",
        "plt.xlabel('Interations')\n",
        "plt.ylabel('Fitness')\n",
        "plt.title('Convergence of Fitness over Iterations using GA')\n",
        "plt.savefig('Leukaemiamattest_ga.pdf')\n",
        "plt.savefig('Leukaemiamattest_ga.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RIXqesIWRqzE",
        "outputId": "9934cab2-6723-4ab0-cccd-22ac969129ca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "population size:  30\n",
            "\n",
            "SIMULATED ANNEALING\n",
            "\n",
            "Individual \t\t\t\t\t Fitness \t\t\t Accuracy\n",
            "[0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1] 0.9113183451646084 1.0\n",
            "[0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0] 0.9159156402696382 1.0\n",
            "[0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1] 0.9038228760216724 1.0\n",
            "[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1] 0.9187537521408541 1.0\n",
            "[1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] 0.9287305644442263 1.0\n",
            "[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0] 0.9381882497886311 1.0\n",
            "[1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 0.9349441718095038 1.0\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0] 0.9328396414162812 1.0\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1] 0.9248080185868573 1.0\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0] 0.931682164390383 1.0\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1] 0.9195423321272145 1.0\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1] 0.9255090471622108 1.0\n",
            "[1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0] 0.9164454171405537 1.0\n",
            "[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0] 0.911120230463798 1.0\n",
            "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1] 0.9175421246116994 1.0\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1] 0.9260595668774168 1.0\n",
            "[0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1] 0.9173931026367829 1.0\n",
            "[0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0] 0.9167199576536903 1.0\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1] 0.9265607291208913 1.0\n",
            "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1] 0.9112961558266878 1.0\n",
            "[0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] 0.9375783120341805 1.0\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0] 0.9396989706511096 1.0\n",
            "[0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1] 0.9046204066671767 1.0\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0] 0.9306140611571236 1.0\n",
            "[1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1] 0.9309925818077427 1.0\n",
            "[0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] 0.930325999564308 1.0\n",
            "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0] 0.9186879994780673 1.0\n",
            "[1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] 0.9299924762489266 1.0\n",
            "[0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1] 0.917960774025548 1.0\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0] 0.9249196029374138 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Individual:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "Best individual accuracy:  1.0\n",
            "Best individual fitness:  0.9553374988221943\n",
            "No of selected features:  2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}