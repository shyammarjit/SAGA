{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMl-e49Is7-8",
        "outputId": "522f8feb-21df-4032-f929-4faf2055c9e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r3MpHK8vbYds"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random, math, glob, copy, pickle, warnings\n",
        "from time import process_time\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqgGY9I9ZzDs"
      },
      "source": [
        "# Feature Dropping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yvOs5BLJZyex"
      },
      "outputs": [],
      "source": [
        "def dropping(x_vector, y_vector, input_percentage):\n",
        "    #global mi_pcc, mi_pcc_sort\n",
        "    # remove the lowest k percentage features from mi_pcc\n",
        "    cutoff = int(math.floor(input_percentage*(x_vector.shape[1])))\n",
        "\n",
        "    fecture_vector = list(x_vector.columns)\n",
        "    removed_feature_list, selected_features = [], []\n",
        "    for i in range(0, cutoff):\n",
        "      for j in range(0, mi_pcc_sort.shape[0]):\n",
        "            if(mi_pcc_sort[i]==mi_pcc[j]):\n",
        "                removed_feature_list.append(fecture_vector[j])\n",
        "    \n",
        "    for k in fecture_vector:\n",
        "        st = 1\n",
        "        for i in removed_feature_list:\n",
        "            if(i==k):\n",
        "                st = 0\n",
        "                break\n",
        "        if(st==1):\n",
        "            selected_features.append(k)\n",
        "    \n",
        "    data = x_vector[selected_features]\n",
        "\n",
        "    mi_selected_features = mutual_info_classif(data, y_vector)\n",
        "    return data, mi_selected_features\n",
        "def hybrid(x_vector, y_vector, percentage):\n",
        "    \"\"\"\n",
        "    Input:  x_vector: 2D array shape of (no_of_samples, no_of_features)\n",
        "            y_vector: 1D array shape of (no_of_sample, )\n",
        "    Output: data: which is equal to x_vector shape of (no_of_samples, no_of_selected_features)\n",
        "    Functionality:  Select the top k percentage of features based on mi and pcc.\n",
        "                    Adopted from paper: https://sci-hub.se/10.1109/calcon49167.2020.9106516\n",
        "    \"\"\"\n",
        "    #global mi_selected_features\n",
        "    global sort_features_list, mi_pcc, mi_pcc_sort\n",
        "\n",
        "    feature_pcc, selected_features, removed_feature_list = [], [], []\n",
        "    a = 0.9\n",
        "    \n",
        "    # Drop constant features\n",
        "    x_vector = x_vector.loc[:,x_vector.apply(pd.Series.nunique) != 1]\n",
        "\n",
        "    # calculate the mutual information between class and feature vector\n",
        "    mi = mutual_info_classif(x_vector, y_vector)\n",
        "\n",
        "    # calculate the pcc between feature to feature\n",
        "    fecture_vector = list(x_vector.columns)\n",
        "    corr_matrix = x_vector.corr()\n",
        "    corr_matrix = abs(np.array(corr_matrix))\n",
        "    for i in range(0, len(corr_matrix)):\n",
        "        feature_pcc.append((np.sum(corr_matrix[i]) - 1)/(len(corr_matrix)-1))\n",
        "    \n",
        "    # compute the final rank value for feature vector\n",
        "    mi_pcc = a*mi - (1-a)*np.array(feature_pcc)\n",
        "\n",
        "    # remove the lowest k percentage features from mi_pcc\n",
        "    cutoff = int(math.floor(percentage*(x_vector.shape[1])))\n",
        "\n",
        "    # sort the array in ascending order\n",
        "    mi_pcc_sort = mi_pcc.copy()\n",
        "    mi_pcc_sort.sort()\n",
        "\n",
        "    sort_features_list = []\n",
        "    mi_sorted = []\n",
        "    for i in range(0, mi_pcc_sort.shape[0]):\n",
        "        for j in range(0, mi_pcc.shape[0]):\n",
        "            if(mi_pcc_sort[i]==mi_pcc[j]):\n",
        "                sort_features_list.append(fecture_vector[j])\n",
        "                #mi_sorted.append()\n",
        "                mi_pcc[j] = 100000000\n",
        "                break\n",
        "    \n",
        "    \n",
        "    removed_feature_list = sort_features_list[0:cutoff]\n",
        "    selected_features = sort_features_list[cutoff:]\n",
        "    \n",
        "    print(\"No of removed features: \", len(removed_feature_list))\n",
        "    print(\"No of selected features: \", len(selected_features))\n",
        "    if(x_vector.shape[1]>1000):\n",
        "        # microarray dataset\n",
        "        pass\n",
        "    else:\n",
        "        print(\"Deleted feature vectors list: \", removed_feature_list)\n",
        "        print(\"Selected feature vectors list: \", selected_features)\n",
        "\n",
        "    # create the x data based on selected feature vector\n",
        "    data = x_vector[selected_features]\n",
        "\n",
        "    \"\"\"\n",
        "    compute the mutual information of the selected feature vector.\n",
        "    which will be using as an 3rd obejectine function for the GA and SA.\n",
        "    \"\"\"\n",
        "    mi_selected_features = mutual_info_classif(data, y_vector)\n",
        "    return data, mi_selected_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jGnUyDbuGIj9"
      },
      "outputs": [],
      "source": [
        "def check_overlapping_for_cluster(pop):\n",
        "    \"\"\"\n",
        "    Input: population, population_fitness, population_accuracy\n",
        "    Output: population, population_fitness, population_accuracy\n",
        "    Functionality:  Takes an population and checks if there are\n",
        "                    multiple copies of a individual then remove\n",
        "                    all these copies.\n",
        "    \"\"\"\n",
        "    enable_output = False # to show the results\n",
        "    pop_copy = pop.copy()\n",
        "    remove_index = []\n",
        "    for i in range(0, len(pop)):\n",
        "        counter = i\n",
        "        for j in pop[i+1:]:\n",
        "            counter += 1\n",
        "            \"\"\"\n",
        "            If two individuals are same then store these same\n",
        "            indiviual's index number for delete.\n",
        "            \"\"\"\n",
        "            if(isEqual(pop[i], j)):\n",
        "                remove_index.append(counter)\n",
        "    remove_index = list(set(remove_index))\n",
        "    remove_index.sort(reverse = True)\n",
        "    \n",
        "    # delete the copy individuals from populations\n",
        "    for i in remove_index:\n",
        "        del pop_copy[i]\n",
        "    \n",
        "    if(enable_output):\n",
        "        if(len(pop_copy) == len(pop)):\n",
        "            print(\"\\nNo overlapping has been occured!!\")\n",
        "            print(\"Current population size: \", len(pop_copy))\n",
        "        else:\n",
        "            print(\"Overlapping occured. Current population size: \", len(pop_copy))\n",
        "    \n",
        "    return pop_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "VgKDBt7uGRBZ"
      },
      "outputs": [],
      "source": [
        "def hammingDist(ind1, ind2):\n",
        "    \"\"\"\n",
        "    Input: two individual ind1 and ind2\n",
        "    Output: an integer value\n",
        "    Functionality: compute the hamming distance between two individuals\n",
        "    \"\"\"\n",
        "    i, count = 0, 0\n",
        "    while(i < len(ind1)):\n",
        "        if(ind1[i]!= ind2[i]):\n",
        "            count += 1\n",
        "        i += 1\n",
        "    return count\n",
        "\n",
        "def cal_similarity(ind_datapoint, cluster_datapoint, ind_acc, cluster_acc):\n",
        "    esp = 0.7\n",
        "    # compute the hamming distance between the cluster_datapoint and ind_datapoint\n",
        "    hamming_dist = hammingDist(cluster_datapoint, ind_datapoint)\n",
        "    # difference between classification accuracy\n",
        "    diff_acc = abs(ind_acc - cluster_acc)\n",
        "    similarity = esp*(1/diff_acc) + (1-esp)*(1/hamming_dist)\n",
        "    return similarity\n",
        "\n",
        "def get_random_pop(size):\n",
        "    random_population = []\n",
        "    for i in range(0, size):\n",
        "        ind = get_individual()\n",
        "        if(np.sum(np.array(ind))==0):\n",
        "            ind = get_individual()\n",
        "        random_population.append(ind)\n",
        "\n",
        "    # check there is any overlapping in between or not\n",
        "    random_population = check_overlapping_for_cluster(random_population)\n",
        "\n",
        "    return random_population\n",
        "\n",
        "def goodness(input_cluster, cluster_acc):\n",
        "    final_ind = []\n",
        "    if(len(input_cluster)==1):\n",
        "        return input_cluster[0]\n",
        "    input_cluster = np.array(input_cluster)\n",
        "    gij = []\n",
        "    for ith_feature in range(0, input_cluster.shape[1]):\n",
        "        numerator, denominator = 0, 0\n",
        "        for no_of_inds in range(0, input_cluster.shape[0]):\n",
        "            numerator += input_cluster[no_of_inds][ith_feature]*cluster_acc[no_of_inds]\n",
        "            denominator += input_cluster[no_of_inds][ith_feature]\n",
        "        temp = numerator/denominator\n",
        "        gij.append(temp)\n",
        "    x = np.array(gij)\n",
        "    t_mean = np.mean(x[~np.isnan(x)])\n",
        "    for ith_feature in range(0, len(gij)):\n",
        "        if(np.isnan(gij[ith_feature])):\n",
        "            # if value is nan then just simply put 0\n",
        "            final_ind.append(0)\n",
        "            continue\n",
        "        if(gij[ith_feature]>=t_mean):\n",
        "            final_ind.append(1)\n",
        "        else:\n",
        "            final_ind.append(0)\n",
        "    return final_ind\n",
        "\n",
        "def CBPI(population_size):\n",
        "    \"\"\"\n",
        "    Input: an 2D array of shape (population_size, no_of_features)\n",
        "    Output: an 2D array of shape (population_size, no_of_features)\n",
        "    Functionality: Cluster based population generation\n",
        "    \"\"\"\n",
        "    population, population_fit, population_acc = [], [], []\n",
        "    random_pop = get_random_pop(4*population_size)\n",
        "    no_cluster_center = population_size # m = no_cluster_center i.e. should be \n",
        "    \n",
        "    # Randomly Initialize the cluster center\n",
        "    cluster_centers = random.sample(random_pop, no_cluster_center)\n",
        "\n",
        "    # now discard the cluster centers individuals from populations\n",
        "    remove_index = []\n",
        "    for i in range(0, len(random_pop)):\n",
        "        flag = 0\n",
        "        for j in range(0, len(cluster_centers)):\n",
        "            if(isEqual(random_pop[i], cluster_centers[j])):\n",
        "                flag = 1\n",
        "                break\n",
        "        if(flag==1):\n",
        "            remove_index.append(i)\n",
        "\n",
        "    remove_index.sort(reverse = True)\n",
        "    for i in remove_index:\n",
        "        del random_pop[i]\n",
        "    \n",
        "    #------------------------------------------------------------\n",
        "    # find the fitness of the non-cluter center individual\n",
        "    non_cluster_pop_fit, non_cluster_pop_acc = [], []\n",
        "\n",
        "    for i in range(0, len(random_pop)):\n",
        "        ind_fit_acc = getFitness(random_pop[i])\n",
        "        non_cluster_pop_fit.append(ind_fit_acc[0])\n",
        "        non_cluster_pop_acc.append(ind_fit_acc[1])\n",
        "    #------------------------------------------------------------\n",
        "    # find the fitness of the cluster centers --> individual\n",
        "    cluster_pop_fit, cluster_pop_acc = [], []\n",
        "    for i in range(0, len(cluster_centers)):\n",
        "        ind_fit_acc = getFitness(cluster_centers[i])\n",
        "        cluster_pop_fit.append(ind_fit_acc[0])\n",
        "        cluster_pop_acc.append(ind_fit_acc[1])\n",
        "\n",
        "    #-----------------------------------------------------------\n",
        "    # Assign the individual to a particular cluster\n",
        "    ind_belongs_to_cluter = []\n",
        "    for i in range(0, len(random_pop)):\n",
        "        ind_fit = non_cluster_pop_fit[i]  # fitness of the current individual\n",
        "        ind_acc = non_cluster_pop_acc[i]  # accuracy of the current individual\n",
        "\n",
        "        similar_list  = []\n",
        "        for j in range(0, no_cluster_center):\n",
        "            cluster_fit = cluster_pop_fit[j]  # fitness of the cluster center\n",
        "            cluster_acc = cluster_pop_acc[j]  # accuracy of the cluster center \n",
        "            \n",
        "            # compute similarity between the cluster center and the current individual\n",
        "            similarity = cal_similarity(random_pop[i], cluster_centers[j], ind_acc, cluster_acc)\n",
        "            similar_list.append(similarity)\n",
        "        # get the cluster no which has the highest similarity\n",
        "        ind_belongs_to_cluter.append(similar_list.index(max(similar_list)))\n",
        "    #-----------------------------------------------------------    \n",
        "    #print(random_pop, len(random_pop), ind_belongs_to_cluter, len(ind_belongs_to_cluter))\n",
        "    # now lets form one 3D list in which (cluster_no * no_of_indviduals)\n",
        "    cluster, cluster_fit, cluster_acc = [], [], []\n",
        "\n",
        "    for ith_cluster in range(0, len(cluster_centers)):\n",
        "        temp_ind, temp_fit, temp_acc = [], [], []\n",
        "        temp_ind.append(cluster_centers[ith_cluster])\n",
        "        temp_fit.append(cluster_pop_fit[ith_cluster])\n",
        "        temp_acc.append(cluster_pop_acc[ith_cluster])\n",
        "\n",
        "        for non_cluster_center in ind_belongs_to_cluter:\n",
        "            if(non_cluster_center==ith_cluster):\n",
        "                temp_ind.append(random_pop[non_cluster_center])\n",
        "                temp_fit.append(non_cluster_pop_fit[non_cluster_center])\n",
        "                temp_acc.append(non_cluster_pop_acc[non_cluster_center])\n",
        "        cluster.append(temp_ind)\n",
        "        cluster_fit.append(temp_fit)\n",
        "        cluster_acc.append(temp_acc)\n",
        "\n",
        "    for ith_cluster in range(0, len(cluster)):\n",
        "        ind = goodness(cluster[ith_cluster].copy(), cluster_acc[ith_cluster].copy())\n",
        "        population.append(ind)\n",
        "        temp = getFitness(ind)\n",
        "        population_fit.append(temp[0])\n",
        "        population_acc.append(temp[0])\n",
        "\n",
        "    return population, population_fit, population_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVLCyF4Qk4ME"
      },
      "source": [
        "# SA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "ssJeCgs-a4Bi"
      },
      "outputs": [],
      "source": [
        "#================================ From Indivisuals to selected feature vector===============================\n",
        "def get_features(ind):\n",
        "    \"\"\"\n",
        "    Input: takes an individual of shape (no_of_features, )\n",
        "    Output: retuns name of the selecetd features.\n",
        "    Functionality: converts and indiviual form to an selected feature vector form.\n",
        "    \"\"\"\n",
        "    # store all the feature vectors of the given dataset\n",
        "    all_features = list(x_train.columns)\n",
        "    features_names = []\n",
        "    for i in range(0, len(ind)):\n",
        "        if(ind[i]==1):\n",
        "            features_names.append(all_features[i])\n",
        "    return features_names\n",
        "#============================================================================================\n",
        "\n",
        "#=============================  Fitness Function   ==========================================\n",
        "def getFitness(individual):\n",
        "    \"\"\"\n",
        "    Input: takes an individual of shape (no_of_features, )\n",
        "    Output: retuns a tuple of (fitnesss_value, accuracy)\n",
        "    Functionality: computes the fitness value of the given individual.\n",
        "    \"\"\"\n",
        "    global gamma, y, mi_selected_features\n",
        "    sum_mi = 0\n",
        "\n",
        "    # calculate the total no of features in the dataset.\n",
        "    total_no_features = int(x_train.shape[1])\n",
        "\n",
        "    # get the name of selected feature vectors from individual \n",
        "    selected_features = get_features(individual)\n",
        "\n",
        "    # calculate the no of selected feature vector\n",
        "    selected_no_fectures = len(selected_features)\n",
        "\n",
        "    # If the no of selected feature vector is 0 then return (0, 0)\n",
        "    if(selected_no_fectures==0):\n",
        "        return (0, 0)\n",
        "\n",
        "    # 1st objective function\n",
        "    _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "    x_train_temp = x_train[selected_features]\n",
        "    x_test_temp = x_test[selected_features]\n",
        "    _classifier.fit(x_train_temp, y_train)\n",
        "    predictions = _classifier.predict(x_test_temp)\n",
        "    accuracy = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "    \"\"\"\n",
        "    3rd objective:\n",
        "    compute the mutual information between the selected feature vector and class vector\n",
        "    \"\"\"\n",
        "    for i in range(0, len(individual)):\n",
        "        if(individual[i]==1):\n",
        "            sum_mi += mi_selected_features[i]\n",
        "    sum_mi = sum_mi/selected_no_fectures\n",
        "    obj_3rd = sum_mi\n",
        "\n",
        "    # calculate the final multiobjective fitness function\n",
        "    my_fitness = alpha*accuracy + (1-alpha)*(gamma * ((total_no_features - selected_no_fectures)/total_no_features) + (1-gamma)*obj_3rd)\n",
        "    \n",
        "    return (my_fitness, accuracy)\n",
        "#============================================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "NtXZ4HzYSn-G"
      },
      "outputs": [],
      "source": [
        "class Simulated_Annealing(object):\n",
        "    \n",
        "    def __init__(self, max_iter = 100):\n",
        "        \"\"\"\n",
        "        Intialization of the Hyperparameters of SA.\n",
        "        \"\"\"\n",
        "        self.max_iter = max_iter\n",
        "        self.total_features = int(x_train.shape[1])\n",
        "        # create a dataframe\n",
        "        self.logfile = pd.DataFrame(columns=['fitness','accuracy', 'no_of_features'])\n",
        "\n",
        "    def isValidInd(self, individual):\n",
        "        \"\"\"\n",
        "        Input: Individual of shape (no_of_selected_feature, )\n",
        "        Output: binary i.e. True or False\n",
        "              False: If we have the Invalid Individual\n",
        "              True: If we have the alid Individual\n",
        "        Functionality:  checks whether a individual is valid or not.\n",
        "                      validity means if we have the 0 in all gene positions \n",
        "                      of an individual then that individual is not valid.\n",
        "        \"\"\"\n",
        "        if((set(individual))=={0}):\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "    def find_new_individual(self, individual):\n",
        "        \"\"\"\n",
        "        Input:  Current Individual of shape (no_of_selected_feature, )\n",
        "        Output: New state i.e. Next Individual of shape (no_of_selected_feature, )\n",
        "        Functionality: generates a new solution/individual from the current solution/individual\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        changes: instead of middle point now it's a random point in between \n",
        "        int(0.30*total_features) and celling(0.70total_features)\n",
        "        \"\"\"\n",
        "        position = []\n",
        "        #methods = \"middle\"\n",
        "        methods = \"30-40\"\n",
        "\n",
        "        if(methods == \"30-40\"):\n",
        "            # methods = \"30-40\"\n",
        "            temp_1 = int(self.total_features*0.30)\n",
        "            temp_2 = int(self.total_features*0.70)\n",
        "            end_point = random.randint(temp_1, temp_2)\n",
        "\n",
        "            position.append(random.randint(0, end_point))\n",
        "            position.append(random.randint(end_point+1, self.total_features-1))\n",
        "        else:\n",
        "            # methods = \"middle\"\n",
        "            position.append(random.randint(0, math.floor(self.total_features/2)))\n",
        "            position.append(random.randint(math.floor(self.total_features/2)+1, self.total_features-1))\n",
        "        \n",
        "        for i in range(0, 2):\n",
        "            if individual[position[i]] == 1:\n",
        "                individual[position[i]] = 0\n",
        "            else:\n",
        "                individual[position[i]] = 1\n",
        "        \n",
        "        # check wheather the new state/individual is valid or not\n",
        "        if(self.isValidInd(individual)):\n",
        "            return individual\n",
        "        else:\n",
        "            # if the individual is not valid then generate the new state or new indivisual\n",
        "            return get_individual()\n",
        "\n",
        "    def result(self):\n",
        "        \"\"\"\n",
        "        show the result after the convergence.\n",
        "        \"\"\"\n",
        "        # calculate the no of selected features in optimal individual\n",
        "        no_of_selected_features = 0\n",
        "        for i in range(0, len(self.best_individual)):\n",
        "            if(self.best_individual[i] == 1):\n",
        "                no_of_selected_features += 1\n",
        "        \n",
        "        # get the selected feature vectors name\n",
        "        selected_features = get_features(self.best_individual)\n",
        "        _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "        x_train_temp = x_train[selected_features]\n",
        "        x_test_temp = x_test[selected_features]\n",
        "        _classifier.fit(x_train_temp, y_train)\n",
        "        predictions = _classifier.predict(x_test_temp)\n",
        "        accuracy = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "        return self.best_individual, self.best_fitness, accuracy, no_of_selected_features, self.logfile\n",
        "\n",
        "    def simulated_annealing(self, initial_indivsual):\n",
        "        \"\"\"\n",
        "        Input: initial_indivsual, intitial individual of shape(no_of_features, )\n",
        "        \"\"\"\n",
        "        sa_accuracy, fitness, iter_values, all_ind = [], [], [], []\n",
        "        my_iter = 0\n",
        "        \n",
        "        # get the initial fitness\n",
        "        initial_fitness, intial_acc = getFitness(initial_indivsual)\n",
        "\n",
        "        current_individual, current_fitness, current_acc = initial_indivsual, initial_fitness, intial_acc\n",
        "        self.initial_indivsual = current_individual\n",
        "        \n",
        "        run_wise_fitness, run_wise_accuracy, run_wise_no_of_features = [], [], []\n",
        "\n",
        "        \"\"\"\n",
        "        initial temp is equal to 2*N\n",
        "        where N is the total no of features\n",
        "        \"\"\"\n",
        "        temp = 2*self.total_features\n",
        "\n",
        "        while my_iter < self.max_iter:\n",
        "            next_individual = self.find_new_individual(current_individual)\n",
        "            next_fitness, next_accuracy = getFitness(next_individual)\n",
        "            if current_fitness > next_fitness:\n",
        "                # i.e. bad moves then accept new individual with some probability value\n",
        "                e_x = (my_iter/temp)*((current_fitness-next_fitness)/current_fitness)\n",
        "                probabilty = math.exp(-e_x)\n",
        "                random_value = random.random()\n",
        "                if random_value <= probabilty: # then accept that bad move\n",
        "                    current_individual = next_individual\n",
        "                    current_fitness = next_fitness\n",
        "                    current_acc = next_accuracy\n",
        "            else:\n",
        "                # directly accepts the new state\n",
        "                current_individual = next_individual\n",
        "                current_fitness = next_fitness\n",
        "                current_acc = next_accuracy\n",
        "            # store the fitness, accuracy and no_of_features in a dataframe and then at the end store as a csv file\n",
        "            run_wise_fitness.append(current_fitness)\n",
        "            run_wise_accuracy.append(current_acc)\n",
        "            run_wise_no_of_features.append(len(get_features(current_individual)))\n",
        "            \n",
        "\n",
        "            all_ind.append(np.array(current_individual))\n",
        "            fitness.append(current_fitness)\n",
        "            my_iter += 1\n",
        "            temp = 0.93*temp # 0.93 is the another hyperparameter i.e. it is a cooling factor\n",
        "        self.best_individual = list(all_ind[fitness.index(max(fitness))])\n",
        "        self.best_fitness = max(fitness)\n",
        "        self.logfile['accuracy'] = run_wise_accuracy\n",
        "        self.logfile['fitness'] = run_wise_fitness\n",
        "        self.logfile['no_of_features'] = run_wise_no_of_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "C7IPQJfUNHMW"
      },
      "outputs": [],
      "source": [
        "def isEqual(ind1, ind2):\n",
        "    \"\"\"\n",
        "    Input: two lists (Indivisual_1, Indivisual_2)\n",
        "    Output: boolen value i.e. True or False\n",
        "    Functionality:  If two individual ind1 and ind2 are same then \n",
        "                    output is True.\n",
        "                    otherwise False\n",
        "    \"\"\"\n",
        "    status = False\n",
        "    for k in range(0, len(ind1)):\n",
        "        if(ind1[k] == ind2[k]):\n",
        "            status = True\n",
        "            continue\n",
        "        else:\n",
        "            status = False\n",
        "            break\n",
        "    return status\n",
        "\n",
        "def check_overlapping(pop, pop_fitness, pop_acc):\n",
        "    \"\"\"\n",
        "    Input: population, population_fitness, population_accuracy\n",
        "    Output: population, population_fitness, population_accuracy\n",
        "    Functionality:  Takes an population and checks if there are\n",
        "                    multiple copies of a individual then remove\n",
        "                    all these copies.\n",
        "    \"\"\"\n",
        "    enable_output = False # to show the results\n",
        "    pop_copy = pop.copy()\n",
        "    pop_fitness_copy = pop_fitness.copy()\n",
        "    pop_acc_copy = pop_acc.copy()\n",
        "    remove_index = []\n",
        "    for i in range(0, len(pop)):\n",
        "        counter = i\n",
        "        for j in pop[i+1:]:\n",
        "            counter += 1\n",
        "            \"\"\"\n",
        "            If two individuals are same then store these same\n",
        "            indiviual's index number for delete.\n",
        "            \"\"\"\n",
        "            if(isEqual(pop[i], j)):\n",
        "                remove_index.append(counter)\n",
        "    remove_index = list(set(remove_index))\n",
        "    remove_index.sort(reverse = True)\n",
        "    \n",
        "    # delete the copy individuals from populations\n",
        "    for i in remove_index:\n",
        "        del pop_copy[i]\n",
        "        del pop_fitness_copy[i]\n",
        "        del pop_acc_copy[i]\n",
        "    \n",
        "    if(enable_output):\n",
        "        if(len(pop_copy) == len(pop)):\n",
        "            print(\"\\nNo overlapping has been occured!!\")\n",
        "            print(\"Current population size: \", len(pop_copy))\n",
        "        else:\n",
        "            print(\"Overlapping occured. Current population size: \", len(pop_copy))\n",
        "    \n",
        "    return pop_copy, pop_fitness_copy, pop_acc_copy\n",
        "\n",
        "def get_individual():\n",
        "    \"\"\"\n",
        "    Input: \n",
        "    Output: individual\n",
        "    Functionality:  generate an individual.\n",
        "                    genes are randomly generated.\n",
        "    \"\"\"\n",
        "    individual = []\n",
        "    for i in range(0, x_train.shape[1]):\n",
        "        gene = random.randint(0, 1)\n",
        "        individual.append(gene)\n",
        "    return individual\n",
        "\n",
        "def get_population(population_size):\n",
        "    global sa_all_population_run_wise\n",
        "    \"\"\"\n",
        "    Input: an integer, population_size\n",
        "    Output: SA_generated_population, SA_generated_population_fitness,\n",
        "            SA_generated_population_accuarcy \n",
        "    Functionality:  generate population with twice of the actual population size.\n",
        "                    then remove the repetating indivisuals.\n",
        "                    then choose the best individuals out of the current population.\n",
        "    \"\"\"\n",
        "    population, population_fitness, population_accuracy  = [], [], []\n",
        "    while(len(population)<=population_size):\n",
        "        cbpi_pop, cbpi_pop_fit, cbi_pop_acc = CBPI(population_size)\n",
        "        # First generate population by SA\n",
        "        sa_all_population_run_wise = [] # store the run_wise data\n",
        "        # store the intial population also, so that we can run the same for the GA also\n",
        "        with open('cbpi_pop.txt', 'w') as f:\n",
        "            for item in cbpi_pop:\n",
        "                f.write(\"%s\\n\" % item)\n",
        "\n",
        "        for i in range(0, population_size):\n",
        "            #ind = get_individual() # get the randomly generated individual\n",
        "            ind = cbpi_pop[i]#cbpi_population_sa_ga[i]#\n",
        "            SA = Simulated_Annealing() # get the SA object\n",
        "            SA.simulated_annealing(ind) # pass the randomly genrated individual to the SA\n",
        "            best_individual, fitness, acc, no_of_selected_features, sa_logfile = SA.result() # get the SA generated results\n",
        "            sa_all_population_run_wise.append(sa_logfile)\n",
        "            population.append(best_individual) # store the SA generated output indivisual \n",
        "            population_fitness.append(fitness) # store the SA generated fitness value of the final individual \n",
        "            population_accuracy.append(acc) # store the SA generated accuarcy value of the final individual \n",
        "      \n",
        "        # check the repetation is there or not\n",
        "        population, population_fitness, population_accuracy = check_overlapping(population, population_fitness, population_accuracy)\n",
        "        #break\n",
        "    \n",
        "        \"\"\"\n",
        "        If the current population size is equal to the desired population size then return, else\n",
        "        choose the best indivisuals out the of the current population.\n",
        "        \"\"\"\n",
        "\n",
        "        if(len(population)==population_size):\n",
        "            return population, population_fitness, population_accuracy\n",
        "        else:\n",
        "            \"\"\"\n",
        "            Now choose the best indivisuals out the of the current population.\n",
        "            Sort by accuracy first then sort by fitness.\n",
        "            To implement this use dataframe.\n",
        "            \"\"\"\n",
        "            sa_population, sa_fitness, sa_acc = [], [], []\n",
        "            \n",
        "            #store in a dataframe format\n",
        "            sa_df = create_dataframe(population, population_accuracy, population_fitness)\n",
        "\n",
        "            # sort the dataframe based on first Accuarcy then based on Fitness in decending order.\n",
        "            sa_df.sort_values([\"Accuracy\", \"Fitness\"], axis=0, ascending=False, inplace=True)\n",
        "            \n",
        "            # store all of the columns i.e. Individual, Accuracy, Fitness\n",
        "            sa_population_all = list(sa_df['Individual'])\n",
        "            sa_acc_all = list(sa_df['Accuracy'])\n",
        "            sa_fitness_all = list(sa_df['Fitness'])\n",
        "\n",
        "            # create the population containg best individuals\n",
        "            for i in range(0, population_size):\n",
        "                sa_population.append(list(sa_population_all[i]))\n",
        "                sa_fitness.append(sa_fitness_all[i])\n",
        "                sa_acc.append(sa_acc_all[i])\n",
        "            \n",
        "            return sa_population, sa_fitness, sa_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "wMHjgTrj-Fxa"
      },
      "outputs": [],
      "source": [
        "def create_dataframe(ind, acc, fit):\n",
        "    \"\"\"\n",
        "    Input: individual, accuarcy and fitness\n",
        "    output: return a dataframe\n",
        "    \"\"\"\n",
        "    data = {'Individual':['123'], 'Accuracy':['123'], 'Fitness': ['123']}\n",
        "    df = pd.DataFrame(data) # Create DataFrame\n",
        "    for i in range(0, len(ind)):\n",
        "        df.loc[len(df.index)] = [ind[i], acc[i], fit[i]]\n",
        "    df = df.drop(0) # Now delete the fist row\n",
        "    return df\n",
        "\n",
        "def concatenate_dataframe(df1, df2):\n",
        "    \"\"\"\n",
        "    Input: two dataframes\n",
        "    Output: concatenates two input dataframes\n",
        "    \"\"\"\n",
        "    frames = [df1, df2]\n",
        "    concatenated_dataframe = pd.concat(frames)\n",
        "    return concatenated_dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTnKK2BWoxwl"
      },
      "source": [
        "# GA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "9NKKuumfrONS"
      },
      "outputs": [],
      "source": [
        "#==============================================================================================\n",
        "class Solution():    \n",
        "    #structure of the solution \n",
        "    def __init__(self):\n",
        "        self.num_features = None\n",
        "        self.population_size = None\n",
        "        self.num_generations = None\n",
        "        self.best_individual = None\n",
        "        self.best_fitness = None\n",
        "        self.best_accuracy = None\n",
        "        self.final_population = None\n",
        "        self.final_fitness = None\n",
        "        self.final_accuracy = None\n",
        "        self.history = None\n",
        "#==============================================================================================\n",
        "class Genetic_Algorithm(object):\n",
        "\n",
        "    def __init__(self, max_iter):\n",
        "        global num_generations\n",
        "        self.population_size = len(population)\n",
        "        self.save_conv_graph = False\n",
        "        pop = np.ones((len(population), len(population[0])))\n",
        "        for i in range(0, pop.shape[0]):\n",
        "            pop[i] = np.array(population[i])\n",
        "        self.population = pop\n",
        "        self.fitness = np.array(sa_fitness)\n",
        "        self.num_features = x_train.shape[1]\n",
        "        self.accuracy = np.array(sa_accuracy)\n",
        "        self.Leader_fitness = float(\"-inf\")\n",
        "        self.Leader_accuracy = float(\"-inf\")\n",
        "        self.history = []\n",
        "        self.cur_iter = 0\n",
        "        self.num_generations = num_generations\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "        self.solution = None\n",
        "        self.verbose = False\n",
        "\n",
        "        self.prob_cross = 0.7\n",
        "        self.prob_mut = 0.3\n",
        "        self.cross_limit = 10\n",
        "        self.prob_cross_max = 0.7\n",
        "        self.prob_cross_min = 0.6\n",
        "        self.prob_mut_max = 0.4\n",
        "        self.prob_mut_min = 0.3\n",
        "        self.logfile = pd.DataFrame(columns=['fitness','accuracy', 'no_of_features'])\n",
        "\n",
        "    def sort_agents(self, agents, fitness, accuracy):\n",
        "        # sort the agents according to fitness\n",
        "        idx = np.argsort(-fitness)\n",
        "        sorted_agents = agents[idx].copy()\n",
        "        sorted_fitness = fitness[idx].copy()\n",
        "        sorted_accuracy = accuracy[idx].copy()\n",
        "        return sorted_agents, sorted_fitness, sorted_accuracy\n",
        "    \n",
        "    def get_fitness(self, pop):\n",
        "        \"\"\"\n",
        "        Input: population, 2D array\n",
        "        Output: an 1D array\n",
        "        Functionality: calculate the fitness of the population.\n",
        "        \"\"\"\n",
        "        fitness, accuracy = [], []\n",
        "        for i in range(0, len(pop)):\n",
        "            ind_fitness = getFitness(pop[i])\n",
        "            fitness.append(ind_fitness[0])\n",
        "            accuracy.append(ind_fitness[1])\n",
        "        accuracy = np.array(accuracy)\n",
        "        return np.array(fitness), accuracy\n",
        "\n",
        "    def initialize(self):\n",
        "        # set the objective function\n",
        "        self.weight_acc = 0.9\n",
        "        self.population, self.fitness, self.accuracy = self.sort_agents(agents = self.population, fitness = self.fitness, accuracy = self.accuracy)\n",
        "        # save the best fittest individual and it's fitness value\n",
        "        self.Leader_agent, self.Leader_fitness = self.population[0], self.fitness[0]\n",
        "\n",
        "    def save_details(self):\n",
        "        # save some details of every generation\n",
        "        cur_obj = {\n",
        "            'population': self.population,\n",
        "            'fitness': self.fitness,\n",
        "            'accuracy': self.accuracy,\n",
        "        }\n",
        "        self.history.append(copy.deepcopy(cur_obj))\n",
        "\n",
        "    def display(self):\n",
        "        # display the current generation details\n",
        "        if self.verbose:\n",
        "            for i in range(0, len(self.population)):\n",
        "                print(\"agents = \", self.population[i], \" fitness = \", self.fitness[i], \" accuracy = \", self.accuracy[i])\n",
        "\n",
        "    def plot(self):\n",
        "        # plot the convergence graph\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        avg_fitness, avg_accuracy = [], []\n",
        "        for cur in self.history:\n",
        "            avg_fitness.append(np.mean(cur['fitness']))\n",
        "            avg_accuracy.append(np.mean(cur['accuracy']))\n",
        "\n",
        "        plt.plot(np.arange(len(avg_fitness)), avg_fitness,  color = 'r', label = 'fitness')\n",
        "        plt.plot(np.arange(len(avg_accuracy)), avg_accuracy,  color = 'g', label = 'accuracy')\n",
        "        plt.plot(np.arange(len(avg_accuracy)), self.max_fit_per_gen,  color = 'orange', label = 'max-fit')\n",
        "        plt.plot(np.arange(len(avg_accuracy)), self.max_acc_per_gen,  color = 'b', label = 'max-acc')\n",
        "        plt.xlabel('Number of Generations')\n",
        "        plt.ylabel('Average Fitness and Accuracy')\n",
        "        plt.title('Convergence Curve')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        return fig\n",
        "\n",
        "    def post_processing(self):\n",
        "        # post processing steps\n",
        "        fit_acc = self.get_fitness(self.population)\n",
        "        self.fitness = fit_acc[0]\n",
        "        self.accuracy = fit_acc[1]\n",
        "        self.population, self.fitness, self.accuracy = self.sort_agents(agents = self.population, fitness = self.fitness, accuracy = self.accuracy)\n",
        "        \n",
        "        if(self.fitness[0] > self.Leader_fitness):\n",
        "            self.Leader_fitness = self.fitness[0]\n",
        "            self.Leader_agent = self.population[0, :]\n",
        "            self.Leader_accuracy = self.accuracy[0]\n",
        "\n",
        "    def save_solution(self):\n",
        "        # create a solution object\n",
        "        self.solution = Solution()\n",
        "        self.solution.population_size = self.population_size\n",
        "        self.solution.num_generations = self.num_generations\n",
        "\n",
        "        # update attributes of solution\n",
        "        self.solution.best_individual = self.Leader_agent\n",
        "        self.solution.best_fitness = self.Leader_fitness\n",
        "        self.solution.best_accuracy = self.Leader_accuracy\n",
        "        self.solution.final_population = self.population\n",
        "        self.solution.final_fitness = self.fitness\n",
        "        self.solution.final_accuracy = self.accuracy\n",
        "\n",
        "    def crossover(self, parent_1, parent_2):\n",
        "        # perform crossover with crossover probability prob_cross\n",
        "        num_features = parent_1.shape[0]\n",
        "        child_1 = parent_1.copy()\n",
        "        child_2 = parent_2.copy()\n",
        "\n",
        "        for i in range(num_features):\n",
        "            if(np.random.rand() < self.prob_cross):\n",
        "                child_1[i] = parent_2[i]\n",
        "                child_2[i] = parent_1[i]\n",
        "\n",
        "        return child_1, child_2\n",
        "\n",
        "    def mutation(self, chromosome):\n",
        "        # perform mutation with mutation probability prob_mut\n",
        "        num_features = chromosome.shape[0]\n",
        "        mut_chromosome = chromosome.copy()\n",
        "\n",
        "        for i in range(num_features):\n",
        "            if(np.random.rand() < self.prob_mut):\n",
        "                mut_chromosome[i] = 1-mut_chromosome[i]\n",
        "        \n",
        "        return mut_chromosome\n",
        "\n",
        "    def roulette_wheel(self, fitness):\n",
        "        # perform roulette wheel selection\n",
        "        maximum = sum([f for f in fitness])\n",
        "        selection_probs = [f/maximum for f in fitness]\n",
        "        return np.random.choice(len(fitness), p=selection_probs)\n",
        "\n",
        "    def cross_mut(self):\n",
        "        # perform crossover, mutation and replacement\n",
        "        count = 0\n",
        "        #print('Crossover-Mutation phase starting....')\n",
        "\n",
        "        while(count < self.cross_limit):\n",
        "            #print('\\nCrossover no. {}'.format(count+1))\n",
        "            id_1 = self.roulette_wheel(self.fitness)\n",
        "            id_2 = self.roulette_wheel(self.fitness)\n",
        "\n",
        "            if(id_1 != id_2):\n",
        "                child_1, child_2 = self.crossover(self.population[id_1, :], self.population[id_2, :])\n",
        "                child_1 = self.mutation(child_1)\n",
        "                child_2 = self.mutation(child_2)\n",
        "\n",
        "                child = np.array([child_1, child_2])\n",
        "                child_fit_acc = self.get_fitness(child)\n",
        "                child_fitness = child_fit_acc[0]\n",
        "                chile_acc = child_fit_acc[1]\n",
        "                child, child_fitness, chile_acc = self.sort_agents(child, child_fitness, chile_acc)\n",
        "\n",
        "                for i in range(2):\n",
        "                    for j in reversed(range(self.population_size)):\n",
        "                        if(child_fitness[i] > self.fitness[j]):\n",
        "                            #print('child {} replaced with chromosome having id {}'.format(i+1, j+1))\n",
        "                            self.population[j, :] = child[i]\n",
        "                            self.fitness[j] = child_fitness[i]\n",
        "                            self.accuracy[j] = chile_acc[i]\n",
        "                            break\n",
        "                \n",
        "                count+= 1\n",
        "\n",
        "            else:\n",
        "                pass\n",
        "                \"\"\"\n",
        "                print('Crossover failed....')\n",
        "                print('Restarting crossover....\\n')\n",
        "                \"\"\"\n",
        "    \n",
        "    def get_results(self):\n",
        "        # sort the dataframe based on first Accuarcy then based on Fitness in decending order.\n",
        "        self.ga_df.sort_values([\"Accuracy\", \"Fitness\"], axis=0, ascending=False, inplace=True)\n",
        "        \n",
        "        # store all of the columns i.e. Individual, Accuracy, Fitness\n",
        "        best_ind = list(self.ga_df['Individual'])[0]\n",
        "        best_ind_acc = list(self.ga_df['Accuracy'])[0]\n",
        "        best_ind_fit = list(self.ga_df['Fitness'])[0]\n",
        "\n",
        "        # caculate the no of features selected in best individual\n",
        "        count = 0\n",
        "        for i in best_ind:\n",
        "            if(i==1):\n",
        "                count += 1\n",
        "\n",
        "        return best_ind, best_ind_acc, best_ind_fit, count\n",
        "\n",
        "    def run(self):\n",
        "        global ga_run_wise_accuracy, ga_run_wise_fitness, ga_run_wise_no_of_features\n",
        "        self.max_fit_per_gen, self.max_acc_per_gen = [], []\n",
        "        self.initialize()   # initialize the algorithm\n",
        "        self.save_details() # save the initial details\n",
        "        self.max_fit_per_gen.append(np.max(self.fitness))\n",
        "        self.max_acc_per_gen.append(np.max(self.accuracy))\n",
        "\n",
        "        # create the dataframe to store the population and it's fitness value and the accuracy\n",
        "        self.ga_df = create_dataframe(self.population, self.accuracy, self.fitness)\n",
        "        ga_run_wise_accuracy, ga_run_wise_fitness, ga_run_wise_no_of_features = [], [], []\n",
        "        for generation in range(self.num_generations):    # while the end criterion is not met\n",
        "            ga_run_wise_accuracy.append(self.accuracy)\n",
        "            ga_run_wise_fitness.append(self.fitness)\n",
        "            for ind in self.population:\n",
        "                ga_run_wise_no_of_features.append(len(get_features(ind)))\n",
        "            #print(self.fitness)\n",
        "            #print(self.accuracy)\n",
        "\n",
        "            self.cross_mut()\n",
        "\n",
        "            self.cur_iter+= 1\n",
        "\n",
        "            # store all the population and fitness and the accuracy in the dataframe format\n",
        "            # add current individual, accuracy and fitness in the dataframe\n",
        "            self.ga_df_next = create_dataframe(self.population, self.accuracy, self.fitness)\n",
        "            self.ga_df = concatenate_dataframe(self.ga_df_next, self.ga_df)\n",
        "\n",
        "            \"\"\"\n",
        "            # Adopt the crossover and mutation probability\n",
        "            f_dash is the fitness of one of the parent\n",
        "            f_avg is the average fitness of the population.\n",
        "            f is the fitness of the one for mutation. i.e. kind of a thershold value.\n",
        "            \"\"\"\n",
        "\n",
        "            if(cross_mut == \"adaptive\"):\n",
        "                f_avg = np.mean(self.fitness)\n",
        "                # for crossover\n",
        "                f_dash = self.fitness[random.randint(0, int(self.fitness.shape[0]/2))]\n",
        "                if(f_dash > f_avg):\n",
        "                    self.prob_cross = self.prob_cross_max - generation*((self.prob_cross_max - self.prob_cross_min)/self.num_generations)\n",
        "                else:\n",
        "                    self.prob_cross = self.prob_cross_max\n",
        "            \n",
        "                # for mutation\n",
        "                f = 0.80\n",
        "                if(f>f_avg):\n",
        "                    self.prob_mut = self.prob_mut_min + generation*((self.prob_mut_max - self.prob_mut_min)/self.num_generations)\n",
        "                else:\n",
        "                    self.prob_mut = self.prob_mut_min\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "            #----------------------------------------------\n",
        "\n",
        "            self.post_processing()          # do the post processing steps\n",
        "            self.display()                  # display the details of 1 iteration\n",
        "            self.save_details()             # save the details\n",
        "            self.max_fit_per_gen.append(np.max(self.fitness))\n",
        "            self.max_acc_per_gen.append(np.max(self.accuracy))\n",
        "\n",
        "        fit_acc = getFitness(self.Leader_agent)\n",
        "        self.Leader_fitness = fit_acc[0]\n",
        "        self.Leader_accuracy = fit_acc[1]\n",
        "\n",
        "        self.save_solution()\n",
        "\n",
        "        if(self.save_conv_graph):\n",
        "            fig = self.plot()\n",
        "            fig.savefig('convergence_curve_genetic_algo.jpg')\n",
        "\n",
        "        #print('\\n-------------  Leader Agent  ---------------')\n",
        "        #print('Fitness: {}'.format(self.Leader_fitness))\n",
        "        #print('Number of Features: {}'.format(int(np.sum(self.Leader_agent))))\n",
        "        #print('----------------------------------------\\n')\n",
        "        \n",
        "        return self.save_solution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "3E8F7FlO4acD"
      },
      "outputs": [],
      "source": [
        "def get_data(file_name):\n",
        "    global mi_selected_features, dichotomas, sort_features_list, percentage\n",
        "    \"\"\"\n",
        "    Input: file name\n",
        "    Output: x_train, x_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    try:\n",
        "        \n",
        "        _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "        _classifier.fit(x_train, y_train)\n",
        "        predictions = _classifier.predict(x_test)\n",
        "        total_acc = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "    except:\n",
        "        df = pd.read_csv(file_name)\n",
        "        tot_features = len(df.columns)-1\n",
        "        total_features = tot_features\n",
        "        x, y = df[df.columns[:tot_features]], df[df.columns[-1]]\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y)\n",
        "        _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "        _classifier.fit(x_train, y_train)\n",
        "        predictions = _classifier.predict(x_test)\n",
        "        total_acc = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "    print(\"Total features: \",total_features)\n",
        "    print(\"Accuracy, taking all features: \", total_acc*100)\n",
        "\n",
        "    # if total no of features less than 90% then don't need to drop features\n",
        "    if(dropping_way == 'static'):\n",
        "        # drop 25 % of the data directly\n",
        "        #percentage = 0.995\n",
        "        x_train, mi_selected_features = hybrid(x_train, y_train, percentage)\n",
        "        fecture_vectors = list(x_train.columns)\n",
        "        x_test = x_test[fecture_vectors]\n",
        "        return x_train, x_test, y_train, y_test\n",
        "    else:\n",
        "        if(total_features<10):\n",
        "            return x_train, x_test, y_train, y_test\n",
        "        elif(total_features<20):\n",
        "            # if no of features less than 20 then do only one time 25% features dropping\n",
        "            # feature dropping\n",
        "            percentage = 0.25\n",
        "            x_train, mi_selected_features = hybrid(x_train, y_train, percentage)\n",
        "            fecture_vectors = list(x_train.columns)\n",
        "            x_test = x_test[fecture_vectors]\n",
        "            return x_train, x_test, y_train, y_test\n",
        "        else:\n",
        "            if(dichotomas):\n",
        "                run_time = 1\n",
        "                while(True):\n",
        "                    if(x_train.shape[1]<20):\n",
        "                        # don't revome any more features\n",
        "                        break\n",
        "                    # drop25\n",
        "                    percentage25 = 0.25\n",
        "                    if(run_time==1):\n",
        "                        x_train25, mi_selected_features25 = hybrid(x_train, y_train, percentage25)\n",
        "                        fecture_vectors = list(x_train25.columns)\n",
        "                        x_test25 = x_test[fecture_vectors]\n",
        "\n",
        "                    else:\n",
        "                        x_train25, mi_selected_features25 = dropping(x_train, y_train, percentage25)\n",
        "                        fecture_vectors = list(x_train25.columns)\n",
        "                        x_test25 = x_test[fecture_vectors]\n",
        "                    \n",
        "                    run_time += 1\n",
        "\n",
        "                    _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "                    _classifier.fit(x_train25, y_train)\n",
        "                    predictions = _classifier.predict(x_test25)\n",
        "                    acc25 = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "              \n",
        "                    # drop50\n",
        "                    percentage50 = 0.50\n",
        "                    x_train50, mi_selected_features50 = dropping(x_train, y_train, percentage50)\n",
        "                    \n",
        "                    fecture_vectors = list(x_train50.columns)\n",
        "                    x_test50 = x_test[fecture_vectors]\n",
        "\n",
        "                    _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "                    _classifier.fit(x_train50, y_train)\n",
        "                    predictions = _classifier.predict(x_test50)\n",
        "                    acc50 = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "                    # drop50\n",
        "                    percentage75 = 0.75\n",
        "                    x_train75, mi_selected_features75 = dropping(x_train, y_train, percentage75)\n",
        "                    fecture_vectors = list(x_train75.columns)\n",
        "                    x_test75 = x_test[fecture_vectors]\n",
        "\n",
        "                    _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "                    _classifier.fit(x_train75, y_train)\n",
        "                    predictions = _classifier.predict(x_test75)\n",
        "                    acc75 = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "                    ##\n",
        "                    print(\"Dropping: \", total_acc, acc25, acc50, acc75)\n",
        "                    if(acc50 >= acc25):\n",
        "                        \n",
        "                        if(acc75 >= acc50):\n",
        "                            # drop 75% of the data\n",
        "                            x_train, x_test = x_train75, x_test75\n",
        "                            total_acc = acc75\n",
        "                            mi_selected_features = mi_selected_features75\n",
        "                            cutoff = int(math.floor(0.75*(x_train.shape[1])))\n",
        "                            sort_features_list = sort_features_list[0:cutoff]\n",
        "                            print(acc75)\n",
        "                          \n",
        "                          \n",
        "                        else:\n",
        "                            #drop 50% of the data\n",
        "                            x_train, x_test = x_train50, x_test50\n",
        "                            total_acc = acc50\n",
        "                            mi_selected_features = mi_selected_features50\n",
        "                            cutoff = int(math.floor(0.50*(x_train.shape[1])))\n",
        "                            sort_features_list = sort_features_list[0:cutoff]\n",
        "                            print(acc50)\n",
        "                  \n",
        "                    elif(acc25>=total_acc):\n",
        "                        #drop 25% of the data\n",
        "                        x_train, x_test = x_train25, x_test25\n",
        "                        total_acc = acc25\n",
        "                        mi_selected_features = mi_selected_features25\n",
        "                        cutoff = int(math.floor(0.25*(x_train.shape[1])))\n",
        "                        sort_features_list = sort_features_list[0:cutoff]\n",
        "                        print(acc25)\n",
        "                    else:\n",
        "                        break\n",
        "                    run_time = run_time +1\n",
        "                  \n",
        "                return x_train, x_test, y_train, y_test\n",
        "        \n",
        "            else:\n",
        "                percentage = 0.25\n",
        "                # drop the features until the convergence criteria satisfied\n",
        "                while(True):\n",
        "                    #print(percentage, total_acc)\n",
        "                    if(x_train.shape[1]<20):\n",
        "                        # don't revome any more features\n",
        "                        break\n",
        "                    x_train, mi_selected_features  = hybrid(x_train, y_train, percentage)\n",
        "                    fecture_vectors = list(x_train.columns)\n",
        "                    x_test = x_test[fecture_vectors]\n",
        "\n",
        "                    _classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "                    _classifier.fit(x_train, y_train)\n",
        "                    predictions = _classifier.predict(x_test)\n",
        "                    total_acc_new = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "                    if(total_acc_new >= total_acc):\n",
        "                        #total_acc = total_acc_new\n",
        "                        x_train_to_save, x_test_to_save, y_train_to_save, y_test_to_save = x_train.copy(), x_test.copy(), y_train.copy(), y_test.copy()\n",
        "                        #percentage = percentage + 0.05\n",
        "                    else:\n",
        "                        break\n",
        "                return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "GGAXGHffOzTU"
      },
      "outputs": [],
      "source": [
        "def display_results():\n",
        "    \"\"\"\n",
        "    display the results\n",
        "    \"\"\"\n",
        "    if(x_train.shape[1]>1000):\n",
        "        print(\"Fitness\", \"\\t\"*3, \"Accuracy\")\n",
        "        for i in range(0, len(population)):\n",
        "            print(sa_fitness[i], sa_accuracy[i])\n",
        "    else:\n",
        "        print(\"Individual\", \"\\t\"*5, \"Fitness\", \"\\t\"*3, \"Accuracy\")\n",
        "        for i in range(0, len(population)):\n",
        "            print(population[i], sa_fitness[i], sa_accuracy[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aI92SALnVM1",
        "outputId": "cfde662a-94cd-4b74-fc93-0b6c29363e52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/Feature Selection/dataset/microarray/Leukaemiamattest.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/SRBCTGENE.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/dlbcl.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/braintumor.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/AMLGSE2191.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/MLLmattest.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/prostatemattest.csv', '/content/drive/MyDrive/Feature Selection/dataset/microarray/lung.csv']\n"
          ]
        }
      ],
      "source": [
        "files = glob.glob(\"/content/drive/MyDrive/Feature Selection/dataset/microarray/*.csv\")\n",
        "dropping_verbose = False\n",
        "dichotomas = True\n",
        "dropping_way = 'static'\n",
        "print(files)\n",
        "#Adaptive\n",
        "cross_mut = 'adaptive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo8-rro4svTd",
        "outputId": "f2c8ec63-68a5-4f94-b534-6ee2143b9bed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Feature Selection/dataset/microarray/Leukaemiamattest.csv',\n",
              " '/content/drive/MyDrive/Feature Selection/dataset/microarray/SRBCTGENE.csv',\n",
              " '/content/drive/MyDrive/Feature Selection/dataset/microarray/dlbcl.csv',\n",
              " '/content/drive/MyDrive/Feature Selection/dataset/microarray/braintumor.csv',\n",
              " '/content/drive/MyDrive/Feature Selection/dataset/microarray/AMLGSE2191.csv',\n",
              " '/content/drive/MyDrive/Feature Selection/dataset/microarray/MLLmattest.csv',\n",
              " '/content/drive/MyDrive/Feature Selection/dataset/microarray/prostatemattest.csv',\n",
              " '/content/drive/MyDrive/Feature Selection/dataset/microarray/lung.csv']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ6HG6UcjV_-",
        "outputId": "8ac4b06e-906b-4955-8100-281575dda3a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Feature Selection/dataset/microarray/Leukaemiamattest.csv\n",
            "Total features:  5147\n",
            "Accuracy, taking all features:  86.66666666666667\n",
            "No of removed features:  5127\n",
            "No of selected features:  20\n",
            "Accuarcy with all the features:  93.33333333333333\n"
          ]
        }
      ],
      "source": [
        "data_type = \"microarray\"\n",
        "# Calculate the percentage of the\n",
        "no_of_wanted_features = 20\n",
        "percentage = (100 - (no_of_wanted_features/5147)*100)/100\n",
        "total_run = 10\n",
        "file_name = files[0]\n",
        "print(file_name)\n",
        "x_train, x_test, y_train, y_test = get_data(file_name)\n",
        "\n",
        "mi_selected_features = mutual_info_classif(x_train, y_train)\n",
        "\n",
        "# Train with all the features\n",
        "_classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "_classifier.fit(x_train, y_train)\n",
        "predictions = _classifier.predict(x_test)\n",
        "total_acc_new = accuracy_score(y_true = y_test, y_pred = predictions)\n",
        "print('Accuarcy with all the features: ', total_acc_new*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8ffxAeuaa2O"
      },
      "source": [
        "#SAGA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RIXqesIWRqzE",
        "outputId": "797d00a3-79be-4517-b661-12571c6f662b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "population size:  30\n",
            "\n",
            "SIMULATED ANNEALING\n",
            "\n",
            "Individual \t\t\t\t\t Fitness \t\t\t Accuracy\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0] 0.9182867692954961 1.0\n",
            "[1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0] 0.9107821841905847 1.0\n",
            "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1] 0.9183048786178568 1.0\n",
            "[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0] 0.9178428123219072 1.0\n",
            "[0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0] 0.910313787771788 1.0\n",
            "[0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0] 0.9099551751659023 1.0\n",
            "[0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0] 0.9241619018133427 1.0\n",
            "[0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0] 0.9230613484709164 1.0\n",
            "[0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0] 0.9232715294969887 1.0\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1] 0.9176575790750859 1.0\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0] 0.9043857257361374 1.0\n",
            "[0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0] 0.9087319997209881 1.0\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0] 0.9174518187050253 1.0\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0] 0.9185204898193239 1.0\n",
            "[1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0] 0.9038286877599091 1.0\n",
            "[0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0] 0.9164535828859037 1.0\n",
            "[0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0] 0.9172643861745372 1.0\n",
            "[0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0] 0.9179733097100897 1.0\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0] 0.9170554594467262 1.0\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0] 0.9381911885137243 1.0\n",
            "[1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1] 0.8898707601744782 1.0\n",
            "[0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0] 0.9040431609680624 1.0\n",
            "[1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] 0.9285262452753797 1.0\n",
            "[1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1] 0.8894667976779014 1.0\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] 0.9151496058973204 1.0\n",
            "[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0] 0.924426015231545 1.0\n",
            "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1] 0.9112216133492377 1.0\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0] 0.9103103956907331 1.0\n",
            "[0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0] 0.9182776238059867 1.0\n",
            "[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1] 0.9239591177175749 1.0\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwcdZ3/8debHIQckEAiPyGYcMQjrggaObySXVABWUBcBUQk7CrrKj9RQUXX1d0oy+qCx+6iLrqIiIKAq/JDVmQh4MFhhiMcYjBGMCckkCGBHDNJPr8/vt8ONZ2emZ4wlZ7ufj8fj3lMdVV19ae6uvvdVd/qbykiMDMzq7ZTowswM7OhyQFhZmY1OSDMzKwmB4SZmdXkgDAzs5ocEGZmVpMDwoYcSXtK+oWktZIuGsD9/kfS6WXWZttH0qckfavRddRD0jOS9mt0HUOBA2KAJL1LUkd+ES3PH0qvb3RdLeZMYBWwa0ScUz1R0mWSuvI2qPydFBFHR8R38jyzJf1qRxc+FFU/F5IelXRkiY83S9KS4riI+OeIeG9ZjzmYImJsRCwa7OVKGi/pUkkr8pefRySdV2O+yyRtkvTCwa5hoBwQAyDpo8BXgH8G9gReBHwNOL6RdRVJGt7oGgbBFOC30fevOL+Y38iVvx/sqOKGsrK3vxJ/bmyfLwNjgZcBuwHHAQuLM0gaA7wdeBp4944ucBsR4b86/kgb9BngHX3MszMpQJblv68AO+dps4AlwDnAE8By4Iw87VBgBTCssKy3Affn4Z2A84A/AE8CVwO752lTgQD+BvgT8AtgGHAR6Vv4H4Gz8jzDC+vyX7mGpcDnK48NzAZ+BVwIrM73P7pQ1+7At/P6rQZ+XJh2LHAf0AncDhzYx3P1WmAe6Y0wD3htHn8Z0A105ef7yBr3vQz4fI3xtwLvJb0BNwCb8zI6C/e7GPgpsBa4C9i/cP+XAjcBTwELgHcWph0D/Dbfbylwbh4/Ebg+r/NTwC+BnQa4zicBHVXzfgS4rvC6ujBv38eBbwC7VL2uPkF6DX23xuPOBn6Vh78LbAHW5+fm43n8YXmbdQLzgVlVz+v5wK/z/Q4AzgAezs/HIuBv87xj8jxb8vKfAfYC/hG4orDM44CH8uPdCrysMO1R4Fzg/vxc/QAYNZDnm+feF8OrXx95+ADgtrz8VcAPCvMFcECdr5k3k14rT5O+LN5WeYwaNT0InNDP58x7gMXA2cCDDf/ca3QBzfIHHAVsKr7gaswzB7gTeAEwKb/hPpenzcr3nwOMIH3grAMm5Ol/AN5UWNY1wHl5+Oy83MmkD4v/BK7M0ypvhMvzm3MX4P2kD7PJwATgf+kZED/KyxiTa/1N4Q0+m/QB/T5S0PwdKQyUp/80v2En5PWYmccfTAq+Q/P9Tie90Xeu8TztTgqX04DhwCn59h55+mXUCIDC/WtOp+cHwGzyh2LV/Z4EDsmP+z3gqjxtTH5jnpGnHUz64Jiepy8H3pCHJwCvysMXkD6wR+S/N1Seq3rXGRhN+vCZVph/HnByHv4ycF1exjjg/wEXVL2uvpBfG7vUeOwez0XeLkcWbu+dn5djSF9G3pRvTyo8r38CXp5rHwG8FdgfEDCT9Fp+VaGmJVU1/CM5IIAXA8/mxxkBfJz0TXpkob7fkIJld1IQvX+Az/dU+g6IK4G/z+s7Cnh9Yb7qgOjtNTMRWAOcmKedTXrv9BYQ3yKF4hnFbV01z83AF0lHKDYBr27o514jH7yZ/oBTgRX9zPMH4JjC7bcAj+bhWaRvVsUX7BPAYXn488CleXhcfgNNybcfBo4o3O+F+YU4vPBG2K8w/RbyB36+fWTlzZJfeBspfJCQPqzm5uHZwMLCtNH5vv8nP+4WcqhVrfvXyWFYGLeAHCBV408DflM17g5gdh6+jP4DYgPpW2QnsCqPL34AzKZ2QHyrcPsY4Hd5+CTgl1Xz/yfw2Tz8J+BvSe0ixXnmAD8hf6D0UXN/63wF8Jk8PI0UGKNJH8DP0vNb6+HAHwuvqy7yN+xeHrvHc8G2AfEJqvY8gBuB0wvP65x+1u/HwNmFmvoKiH8Ari5M24m0VzarUN+7C9O/CHxjgM/3VPoOiMuBS4DJNe5bHRC9vWbeA9xRmCbSl4zeAmIX4FPA3aT370J67p2/iPT+OqiwDb7a13qW/edjifV7EpjYzzHevYDHCrcfy+O2LiMiNhVuryMdkwT4PnCipJ1J30juiYjKsqYAP5LUKamTFBibSR/2FYur6ljcy7QppG9eywvL+0/SnkTFispARKzLg2OBfYCnImJ1jXWfApxTWWZe7j5V61+s77GqcY+RvsnW68KIGJ//Jg7gfisKw8XnfwpwaFX9p5KCEdJx4WOAxyTdJunwPP5fSW/0n0taVKvRMetvnb9PCmqAd5EO3a0j7YmOBu4u1PWzPL5iZURsqGflezEFeEfVur+e9IWgovgaQtLRku6U9FSe/xjSN+p69HguImJLXn5x+/e2nep9vvvzcdIH+m8kPSTpr/uYt7daerzPIn2q92icL4qI9ZEa619N2nO8GrhG0u55ltOAhyPivnz7e8C7JI0YwHoNKgdE/e4gffM+oY95lpHebBUvyuP6FRG/Jb1pjiZ9QHy/MHkx6ZvG+MLfqIhYWlxEYXg56fBSxT5Vy9oITCwsa9eIeHkdZS4Gdpc0vpdp51fVODoirqwxb/XzBOm5Wlpj3u0V/c/Sw2Lgtqr6x0bE3wFExLyIOJ4UpD8mvbmJiLURcU5E7Ec6rv5RSUfUWH5/63wTMEnSQaSgqGz/VaQ9z5cX6totIsYWljPQda2efzFpD6K47mMi4l9q3Sd/ifkhqV1kz4gYD9xA+sCtp54ez4UkkV6j/W7/ATzfz+b/owvjKmFPRKyIiPdFxF6kPcOvSTqgv8ev0uN9ltdjcu+z91iPNaSTXcYA++bR7wH2y2c5rQC+RArdYwZY16BxQNQpIp4GPgNcLOkESaMljcjfpL6YZ7sS+LSkSZIm5vmvGMDDfJ90HPONpDaIim8A50uaApCX39eZU1cDZ0vaO3+Yf6KwHsuBnwMXSdpV0k6S9pc0s7/i8n3/h/RmmpDX/4158jeB90s6NJ/pMkbSWyWNq7GoG4AX51OGh0s6CZhOanwcLI8DkyWNrHP+63NNp+X1GiHpNZJeJmmkpFMl7RYR3aTjzlsAJB0r6YD84fA0ac9uS43l97nOebnXkL4h704KjMq3628CX5b0gvyYe0t6y/Y8KdnjQPE8/yuAv5T0FknDJI3Kp6r29mE3ktTesRLYJOloUmNtcfl7SNqtl/tfDbxV0hH52/E5pC8tt/dXeL3Pd0SsJAXOu/M6/TWpzaSynHcU1m81KdRqbbe+/BR4Rf48GA58kEII1aj9H/JraqSkUaT3eiewIO+R7k9q6zgo//0Z6TPhPQOsa9A4IAYgIi4CPgp8mvTmWEw6Q+jHeZbPAx2ksy8eAO7J4+p1JanB75aIWFUY/1VSI+XPJa0lNVgf2sdyvkkKgfuBe0kfTptIbyZIL7iRpIbs1cC19Dyc0JfTSMdPf0dqQ/kwQER0kBq2/yMvcyHp2Pc2IuJJ0hlP55AO3X0cOLZqnZ+vW0gNgisk9bvciFhL+pA7mfQNdwXPNfxCWu9HJa0hnQRwah4/jXQSwDOkvcyvRcTcGsuvZ52/T2ovuqbqUOQnSM/nnfnx/xd4SX/r1IcLSF9kOiWdGxGLSadqf4rnXtcfo5fPh/xcfYj0Qb+atMd7XWH670iv5UX5Mfaquv8C0imc/07aQ/pL4C8joquO2ut6vrP35fV4ktTAXgyg1wB3SXom1352DPC3D3nbvYPURvIkKfA7SGFX8y6kMwBXkV5jbwLeGhHPkE7q+ElEPJD3blZExArSe//YwmGoHapyZoq1sPwN7xsRUX2Iw8wGidLvQ5YAp/YRWk3FexAtSNIuko7JhzL2Bj5LOrXVzAZRPiw3PrfLfIrUDnNng8saNA6I1iTgn0i7//eSznr6TEMrMmtNh5NOb68cKjshItY3tqTB40NMZmZWk/cgzMysprI79jqK1Ao/jPRrxH+pmj4FuJT0o5+nSL+eXFKYvivpTJsfR8RZfT3WxIkTY+rUqYO7AmZmLe7uu+9eFRGTak0rLSAkDSN1cvUmUsv+PEnX5R+EVVwIXB4R35H0F6TT704rTP8cqfO5fk2dOpWOjo7BKd7MrE1Iqv6F/1ZlHmI6hNSnz6J8fvNVbNst9nTS+eoAc4vTJb2a1JXEz0us0czMelFmQOxNz/5blrBtXzvzSf0OQereepykPfL5xBeRuvztlaQzlS7e07Fy5cpBKtvMzKDxjdTnAjMl3Uv6BfFS0q99PwDcUGyPqCUiLomIGRExY9KkmofQzMxsO5XZSL2Unp3ETaaqM66IWEbeg5A0Fnh7RHTmfkneIOkDpJ4TR0p6JiK2t+dGMzMboDIDYh4wTdK+pGA4mdRny1a5Q7uncodknySd0UREnFqYZzYww+FgZrZjlXaIKXc2dhbpohcPky4Q8pCkOZKOy7PNIvVk+AipQfr8suoxM7OBaZlfUs+YMSN8mquZ2cBIujsiZtSaVuoP5cxsB3riF7DifxtdhTXC6MlwwJmDvlgHhFmruPdj8ORveO7CbtY29jjUAWFmfdjwBEw9DV57eaMrsRbR6N9BmNlg2bgKdp7Y6CqshTggzFrB5g2w6RkY5YCwweOAMGsFG59M/70HYYPIAWHWCjauSv8dEDaIHBBmrcABYSVwQJi1AgeElcABYdYKHBBWAgeEWSuoBMTI3Rtbh7UUB4RZK9i4CkZOgJ3821cbPA4Is1bgH8lZCRwQZq3AAWElcECYtQIHhJXAAWHWChwQVgIHhFmzi3BAWCkcEGbNbvO61FmfA8IGmQPCrNn5R3JWEgeEWbNzQFhJHBBmzW6DA8LK4YAwa3beg7CSOCDMmp0DwkrigDBrdhtXgXaCkeMbXYm1GAeEWbPbuCr14iq/nW1w+RVl1uz8IzkriQPCrNk5IKwkDgizZueAsJI4IMyanQPCSuKAMGtm7qjPSuSAMGtm3WsgNjkgrBSlBoSkoyQtkLRQ0nk1pk+RdLOk+yXdKmlyYfw9ku6T9JCk95dZp1nT8o/krESlBYSkYcDFwNHAdOAUSdOrZrsQuDwiDgTmABfk8cuBwyPiIOBQ4DxJe5VVq1nTckBYicrcgzgEWBgRiyKiC7gKOL5qnunALXl4bmV6RHRFxMY8fueS6zRrXg4IK1GZH7x7A4sLt5fkcUXzgRPz8NuAcZL2AJC0j6T78zK+EBHLSqzVrDk5IKxEjf5mfi4wU9K9wExgKbAZICIW50NPBwCnS9qz+s6SzpTUIalj5cqVO7Jus6HBAWElKjMglgL7FG5PzuO2iohlEXFiRBwM/H0e11k9D/Ag8IbqB4iISyJiRkTMmDRp0mDXbzb0bVwFGg4jdm10JdaCygyIecA0SftKGgmcDFxXnEHSRGlrD2OfBC7N4ydL2iUPTwBeDywosVaz5lT5DYTU6EqsBZUWEBGxCTgLuBF4GLg6Ih6SNEfScXm2WcACSY8AewLn5/EvA+6SNB+4DbgwIh4oq1azpuUfyVmJhpe58Ii4AbihatxnCsPXAtfWuN9NwIFl1mZtav3j0N3Z/3zNYt0SB4SVptSAMBtSNjwBP9kHtnQ3upLBNeVdja7AWpQDwtrHkx0pHA78HIzdv9HVDJ4XzGx0BdaiHBDWPjrnp/8vPsuX5zSrQ6N/B2G246yeD2OmOhzM6uSAsPbROR8mvLLRVZg1DQeEtYdN62DtIzDeAWFWLweEtYfOByG2eA/CbAAcENYeKg3U3oMwq5sDwtrD6vkwfByM3bfRlZg1DQeEtYfO+TDhQJBf8mb18rvFWl8EdN7vw0tmA+SAsNb37KPQvcYN1GYD5ICw1rfaDdRm28MBYa1v9X2p7WH8KxpdiVlTcUBY6+ucD+OmwfDRja7ErKk4IKz1rZ7vw0tm28G9udrzs+lZ+OMVqRF4KIrN8Owf4YD3NroSs6bjgLDtt/Sn0PFBePaxRlfSNw2DF8xqdBVmTccBUZbOB+EPlwLR6ErKsfYRWHYD7PoyOGIu7PGaRlfUOw2HYTs3ugqzpuOAKMsj/w4LvwkjxjW6knIMGwWv/Gd46TkwbGSjqzGzEjggyrJuGYw/EI65r9GVmJltF5/FVJYNy2GXFza6CjOz7eaAKMv65bDLXo2uwsxsuzkgyrBlM2x43HsQZtbUHBBl2LgqnX/vgDCzJuaAKMP6Zem/A8LMmpgDogzrl6f/oxwQZta8HBBl2JADwnsQZtbEHBBlWO+AMLPm54Aow/rlMHJ3d+9gZk3NAVGG9cu892BmTc8BUYb1/hW1mTW/UgNC0lGSFkhaKOm8GtOnSLpZ0v2SbpU0OY8/SNIdkh7K004qs85Bt365z2Ays6ZXWkBIGgZcDBwNTAdOkTS9arYLgcsj4kBgDnBBHr8OeE9EvBw4CviKpPFl1TqoImDDChjtbjbMrLmVuQdxCLAwIhZFRBdwFXB81TzTgVvy8NzK9Ih4JCJ+n4eXAU8Ak0qsdfB0PQVburwHYWZNr8yA2BtYXLi9JI8rmg+cmIffBoyTtEdxBkmHACOBP1Q/gKQzJXVI6li5cuWgFf68+BRXM2sRjW6kPheYKeleYCawFNhcmSjphcB3gTMiYkv1nSPikoiYEREzJk0aIjsY7mbDzFpEmRcMWgrsU7g9OY/bKh8+OhFA0ljg7RHRmW/vCvwU+PuIuLPEOgeX9yDMrEWUuQcxD5gmaV9JI4GTgeuKM0iaKKlSwyeBS/P4kcCPSA3Y15ZY4+BzQJhZiygtICJiE3AWcCPwMHB1RDwkaY6k4/Jss4AFkh4B9gTOz+PfCbwRmC3pvvx3UFm1Dqr1y2HErjB8TKMrMTN7Xkq9JnVE3ADcUDXuM4Xha4Ft9hAi4grgijJrK40vNWpmLaLRjdStZ/0yn+JqZi3BATHY3M2GmbUIB8RginBAmFnLcEAMpu41sHk97OJuNsys+Q04ICRNkHRgGcU0PZ/iamYtpK6AyD2t7ippd+Ae4JuSvlRuaU3Iv6I2sxZS7x7EbhGxhvSr58sj4lDgyPLKalKVPQifxWRmLaDegBie+0V6J3B9ifU0tw0+xGRmraPeH8rNIf0i+lcRMU/SfsDvyytrCFq7EJ5+qO95Vt4Ow0anX1KbmTW5ugIiIq4BrincXgS8vayihpxVd8HNf57OUOrP+FeCVH5NZmYlqysgJH0R+DywHvgZcCDwkdwlRmtb8wjcdmw6bHT4FTBsVN/zj5myY+oyMytZvYeY3hwRH5f0NuBRUmP1L2jW/pLqtf5xmHtUGp71M9h1WmPrMTPbgeoNiMp8bwWuiYin1Q6HUX59Emx4HI6Y63Aws7ZT71lM10v6HfBq4GZJk4AN5ZU1BETAqtvhxR+AiYc0uhozsx2uroCIiPOA1wIzIqIbWAccX2ZhDbd5PWzphp2HyKVMzcx2sHp/ST0a+ADw9TxqL2BGWUUNCV2r0/+R4xtbh5lZg9R7iOnbQBdpLwLStaU/X0pFQ0VXZ/o/ckJj6zAza5B6A2L/iPgi0A0QEeuA1m6lruxBjPAehJm1p3oDokvSLkAASNof2FhaVUNBt/cgzKy91Xua62dJP5DbR9L3gNcBs8sqakhwG4SZtbl6u9q4SdI9wGGkQ0tnR8SqUitrNLdBmFmbq3cPAmAUsDrfZ7okIuIX5ZQ1BGxtg9itsXWYmTVIvX0xfQE4CXgI2JJHB6m7jdbU1QnDx8JOA8lQM7PWUe+n3wnASyKitRumi7pX+/CSmbW1es9iWgSMKLOQIaer0w3UZtbW6t2DWAfcJ+lmCqe3RsSHSqlqKOjyHoSZtbd6A+K6/FcUg1zL0NLV6Ws7mFlbqzcgxkfEV4sjJJ1dQj1DR9dqmHBQo6swM2uYetsgTq8xbvYg1jH0dLsNwszaW597EJJOAd4F7CupeIhpHPBUmYU11JbN0L3GbRBm1tb6O8R0O7AcmAhcVBi/Fri/rKIarvvp9N8d9ZlZG+szICLiMeAx4PAdU84QsbUfJu9BmFn76rMNQtKv8v+1ktYU/tZKWtPfwiUdJWmBpIWSzqsxfYqkmyXdL+lWSZML034mqVPS9duzYs/L1p5cvQdhZu2rv0bqUwEiYlxE7Fr4GxcRu/Z1R0nDgIuBo4HpwCmSplfNdiFweUQcCMwBLihM+1fgtAGsy+BxR31mZv0GxI8qA5J+OMBlHwIsjIhFEdEFXMW217GeDtySh+cWp0fEzaS2jh3PXX2bmfUbEMWrxu03wGXvDSwu3F6SxxXNB07Mw28Dxknao94HkHSmpA5JHStXrhxgeX2o7EG4kdrM2lh/ARG9DA+Wc4GZku4FZpKudb253jtHxCURMSMiZkyaNGnwqnIjtZlZv6e5vjI3RgvYpdAwLSD6aYdYCuxTuD05j9sqIpaR9yAkjQXeHhGdA6i/HN2doGEwfEyjKzEza5j+TnMd9jyWPQ+YJmlfUjCcTPrR3VaSJgJPRcQW4JPApc/j8QZPpaM+qf95zcxaVL1dbQxYRGwCzgJuBB4Gro6IhyTNkXRcnm0WsEDSI8CewPmV+0v6JXANcISkJZLeUlat2+jqdPuDmbW9Ui+XFhE3ADdUjftMYfha4Npe7vuGMmvrk7v6NjMrbw+iqfliQWZmDoiafLlRMzMHRE3egzAzc0BsI8JtEGZmOCC2tXkDbOnyWUxm1vYcENXcD5OZGeCA2Fa3e3I1MwMHxLYqexA+xGRmbc4BUc3XgjAzAxwQ23IbhJkZ4IDYlvcgzMwAB8S2vAdhZgY4ILbV3ZmuA7HTiEZXYmbWUA6Ial2rfQaTmRkOiG11dbr9wcwMB8S2ula7/cHMDAfEtrq9B2FmBg6IbbkNwswMcEBsy9eCMDMDHBA9bdkM3U87IMzMcED0tOmZ9H/Ebo2tw8xsCHBAFG1am/6P2LWxdZiZDQEOiKLuNem/A8LMzAHRgwPCzGwrB0RRJSCGj2tsHWZmQ4ADoqjbbRBmZhUOiCIfYjIz28oBUeSAMDPbygFRtDUg3AZhZuaAKNq0FoaN8sWCzMxwQPTUvcaHl8zMMgdEUfcaGO6AMDODkgNC0lGSFkhaKOm8GtOnSLpZ0v2SbpU0uTDtdEm/z3+nl1nnVt1r3P5gZpaVFhCShgEXA0cD04FTJE2vmu1C4PKIOBCYA1yQ77s78FngUOAQ4LOSyr+Kz6a1PsRkZpaVuQdxCLAwIhZFRBdwFXB81TzTgVvy8NzC9LcAN0XEUxGxGrgJOKrEWhO3QZiZbVVmQOwNLC7cXpLHFc0HTszDbwPGSdqjzvsi6UxJHZI6Vq5c+fwrdkCYmW3V6Ebqc4GZku4FZgJLgc313jkiLomIGRExY9KkSc+/mu417ofJzCwbXuKylwL7FG5PzuO2iohl5D0ISWOBt0dEp6SlwKyq+95aYq1Jt9sgzMwqytyDmAdMk7SvpJHAycB1xRkkTZRUqeGTwKV5+EbgzZIm5MbpN+dx5dm8EbZsdECYmWWlBUREbALOIn2wPwxcHREPSZoj6bg82yxggaRHgD2B8/N9nwI+RwqZecCcPK487snVzKyHMg8xERE3ADdUjftMYfha4Npe7nspz+1RlG+T+2EyMytqdCP10OE9CDOzHhwQFe7q28ysBwdExdbLjTogzMzAAfEc70GYmfXggKjYVGmDcCO1mRk4IJ7jPQgzsx4cEBXdawDB8DGNrsTMbEhwQFR0r02Hl+SnxMwMHBDPcUd9ZmY9OCAq3NW3mVkPDogKB4SZWQ8OiApfbtTMrAcHREX3Gv8GwsyswAFR4UNMZmY9OCAqute4HyYzswIHBECE2yDMzKo4IAA2r4PY4jYIM7MCBwS4HyYzsxocEOCAMDOrwQEBvtyomVkNDggoXE3ObRBmZhUOCPAhJjOzGhwQ4IAwM6vBAQGFy406IMzMKhwQUNiDcBuEmVmFAwJSQOw0AnbaudGVmJkNGQ4IeK6jPqnRlZiZDRkOCEi/g3BHfWZmPTggADb5WhBmZtUcEOBrQZiZ1eCAgHSIyQFhZtZDqQEh6ShJCyQtlHRejekvkjRX0r2S7pd0TB4/UtK3JT0gab6kWWXW6T0IM7NtlRYQkoYBFwNHA9OBUyRNr5rt08DVEXEwcDLwtTz+fQAR8QrgTcBFksoLs+417ofJzKxKmXsQhwALI2JRRHQBVwHHV80TQOWr+27Asjw8HbgFICKeADqBGaVV6j0IM7NtlBkQewOLC7eX5HFF/wi8W9IS4Abg/+bx84HjJA2XtC/wamCf6geQdKakDkkdK1eu3L4qt2xOV5RzQJiZ9dDoRupTgMsiYjJwDPDdfCjpUlKgdABfAW4HNlffOSIuiYgZETFj0qRJ21eB+2EyM6tpeInLXkrPb/2T87iivwGOAoiIOySNAibmw0ofqcwk6XbgkXLKDHjRSbBbdfOImVl7K3MPYh4wTdK+kkaSGqGvq5rnT8ARAJJeBowCVkoaLWlMHv8mYFNE/LaUKkdOgNdfBS98cymLNzNrVqXtQUTEJklnATcCw4BLI+IhSXOAjoi4DjgH+Kakj5AarGdHREh6AXCjpC2kvY7TyqrTzMxqU0Q0uoZBMWPGjOjo6Gh0GWZmTUXS3RFR8yzRRjdSm5nZEOWAMDOzmhwQZmZWkwPCzMxqckCYmVlNDggzM6upZU5zlbQSeGyAd5sIrCqhnKGsHdcZ2nO923GdoT3X+/ms85SIqNlXUcsExPaQ1NHb+b+tqh3XGdpzvdtxnaE917usdfYhJjMzq8kBYWZmNbV7QFzS6AIaoB3XGdpzvdtxnaE917uUdW7rNggzM+tdu+9BmJlZLxwQZmZWU1sGhKSjJC2QtFDSeY2upyyS9pE0V9JvJT0k6ew8fndJN0n6ff4/odG1DjZJwyTdK+n6fHtfSXflbf6DfBGrliFpvKRrJf1O0sOSDm+T7fyR/Np+UNKVkka14raWdKmkJyQ9WBhXc/sq+be8/vdLetX2Pm7bBYSkYcDFwNHAdOAUSa16vdFNwDkRMR04DPhgXtfzgJsjYhpwc77das4GHi7c/gLw5SRWW28AAAU3SURBVIg4AFhNutxtK/kq8LOIeCnwStK6t/R2lrQ38CFgRkT8GenCZCfTmtv6MvLlmQt6275HA9Py35nA17f3QdsuIIBDgIURsSgiuoCrgOMbXFMpImJ5RNyTh9eSPjT2Jq3vd/Js3wFOaEyF5ZA0GXgr8K18W8BfANfmWVpqnSXtBrwR+C+AiOiKiE5afDtnw4FdJA0HRgPLacFtHRG/AJ6qGt3b9j0euDySO4Hxkl64PY/bjgGxN7C4cHtJHtfSJE0FDgbuAvaMiOV50gpgzwaVVZavAB8HtuTbewCdEbEp3261bb4vsBL4dj6s9q18TfeW3s4RsRS4kHRt++XA08DdtPa2Lupt+w7aZ1w7BkTbkTQW+CHw4YhYU5wW6TznljnXWdKxwBMRcXeja9mBhgOvAr4eEQcDz1J1OKnVtjNAPuZ+PCkg9wLGsO1hmLZQ1vZtx4BYCuxTuD05j2tJkkaQwuF7EfHfefTjlV3O/P+JRtVXgtcBx0l6lHT48C9Ix+fH58MQ0HrbfAmwJCLuyrevJQVGK29ngCOBP0bEyojoBv6btP1beVsX9bZ9B+0zrh0DYh4wLZ/pMJLUqHVdg2sqRT72/l/AwxHxpcKk64DT8/DpwE92dG1liYhPRsTkiJhK2ra3RMSpwFzgr/JsrbbOK4DFkl6SRx0B/JYW3s7Zn4DDJI3Or/XKerfstq7S2/a9DnhPPpvpMODpwqGoAWnLX1JLOoZ0nHoYcGlEnN/gkkoh6fXAL4EHeO54/KdI7RBXAy8idZH+zoiobgBrepJmAedGxLGS9iPtUewO3Au8OyI2NrK+wSTpIFKj/EhgEXAG6QtgS29nSf8EnEQ6Y+9e4L2k4+0tta0lXQnMInXr/TjwWeDH1Ni+OSz/g3S4bR1wRkR0bNfjtmNAmJlZ/9rxEJOZmdXBAWFmZjU5IMzMrCYHhJmZ1eSAMDOzmhwQ1tYkPVPHPB+WNHoQH/OEYgeRkuZIOnKwlm82WHyaq7U1Sc9ExNh+5nmU1GPoqgEsd1hEbO5l2mXA9RFxba3pZkOF9yDMSD+qk3Rr4ZoK38u/RP0QqZ+fuZLm5nnfLOkOSfdIuib3dYWkRyV9QdI9wDskvU/SPEnzJf0w/+L3tcBxwL9Kuk/S/pIuk/RXeRlH5A73HsjXANi5sOx/yo/5gKSX5vEz83Luy/cb14Cnz1qUA8LsOQcDHyZdJ2Q/4HUR8W/AMuDPI+LPJU0EPg0cGRGvAjqAjxaW8WREvCoirgL+OyJeExGV6zP8TUTcTuoK4WMRcVBE/KFyR0mjSP3+nxQRryB1wvd3hWWvyo/5deDcPO5c4IMRcRDwBmD9YD4h1t4cEGbP+U1ELImILcB9wNQa8xxGCpBfS7qP1AfOlML0HxSG/0zSLyU9AJwKvLyfx38JqfO5R/Lt75Cu81BR6Wzx7kJtvwa+lPd0xhe6uTZ73ob3P4tZ2yj217OZ2u8PATdFxCm9LOPZwvBlwAkRMV/SbFJfOoNR39baIuJfJP0UOIYUWm+JiN89z8cxA7wHYVaPtUDl2P6dwOskHQAgaYykF/dyv3HA8tzl+qm9LK9oATC1smzgNOC2vgqTtH9EPBARXyD1VPzSelbIrB4OCLP+XQL8TNLciFgJzAaulHQ/cAe9fyj/A6nn3F8DxW/1VwEfy43K+1dGRsQGUi+s1+TDUluAb/RT24clPZhr6Qb+Z8BrZ9YLn+ZqZmY1eQ/CzMxqckCYmVlNDggzM6vJAWFmZjU5IMzMrCYHhJmZ1eSAMDOzmv4/oWL+h3v3osUAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Individual:  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "Best individual accuracy:  1.0\n",
            "Best individual fitness:  0.952111566928721\n",
            "No of selected features:  2\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "alpha = 0.80\n",
        "gamma = 0.70\n",
        "num_generations = 50\n",
        "population_size = 30\n",
        "\n",
        "# ======================.  SA    =========================\n",
        "print(\"population size: \", population_size)\n",
        "print('\\nSIMULATED ANNEALING\\n')\n",
        "population, sa_fitness, sa_accuracy = get_population(population_size)\n",
        "display_results()\n",
        "#######\n",
        "sa_pop_fit, sa_pop_acc, sa_pop_no_of_fe = [], [], []\n",
        "for i in range(0, 30):\n",
        "    df_draft = sa_all_population_run_wise[i]\n",
        "    sa_pop_fit.append(df_draft['fitness'])\n",
        "    sa_pop_acc.append(df_draft['accuracy'])\n",
        "    sa_pop_no_of_fe.append(df_draft['no_of_features'])\n",
        "# now do iter wise mean (column wise mean)\n",
        "sa_pop_fit, sa_pop_acc, sa_pop_no_of_fe = np.array(sa_pop_fit), np.array(sa_pop_acc), np.array(sa_pop_no_of_fe)\n",
        "\n",
        "mean_fit = np.max(sa_pop_fit, axis = 0)\n",
        "mean_acc = np.max(sa_pop_acc, axis = 0)\n",
        "mean_no_of_fe = np.max(sa_pop_no_of_fe, axis = 0)\n",
        "# set the gbest\n",
        "gbest_fit, gbest_acc = mean_fit[0], mean_acc[0]\n",
        "gbest_fitness, gbest_accuracy = [], []\n",
        "for i in range(0, len(mean_fit)):\n",
        "    if(mean_fit[i]>gbest_fit):\n",
        "        gbest_fit = mean_fit[i]\n",
        "        gbest_fitness.append(gbest_fit)\n",
        "    else:\n",
        "        gbest_fitness.append(gbest_fit)\n",
        "for i in range(0, len(mean_acc)):\n",
        "    if(mean_acc[i]>gbest_acc):\n",
        "        gbest_acc = mean_acc[i]\n",
        "        gbest_accuracy.append(gbest_acc)\n",
        "    else:\n",
        "        gbest_accuracy.append(gbest_acc)\n",
        "\n",
        "runs = np.arange(1, len(mean_fit[0:100])+1, 1)\n",
        "plt.plot(runs, gbest_fitness[0:100], color='orange', linewidth = 1.5)\n",
        "#plt.plot(runs, gbest_accuracy[0:100], label = 'accuracy', linewidth = 0.5)\n",
        "#plt.legend()\n",
        "plt.xlabel('Interations')\n",
        "plt.ylabel('Fitness')\n",
        "plt.title('Convergence of Fitness over Iterations using SA')\n",
        "plt.savefig('Leukaemiamattest_sa.pdf')\n",
        "plt.savefig('Leukaemiamattest_sa.png')\n",
        "plt.show()\n",
        "\n",
        "# =====================   GA.   ==========================\n",
        "algo = Genetic_Algorithm(max_iter = 30)\n",
        "solution = algo.run()\n",
        "best_ind, best_ind_acc, best_ind_fit, no_of_selected = algo.get_results()\n",
        "#fig = algo.plot()\n",
        "print(\"Best Individual: \", best_ind)\n",
        "print(\"Best individual accuracy: \", best_ind_acc)\n",
        "print(\"Best individual fitness: \", best_ind_fit)\n",
        "print(\"No of selected features: \", no_of_selected)\n",
        "ga_mean_fit, ga_mean_acc = [], []\n",
        "for i in range(0, len(ga_run_wise_accuracy)):\n",
        "    ga_mean_fit.append(np.max(ga_run_wise_fitness[i]))\n",
        "    ga_mean_acc.append(np.max(ga_run_wise_accuracy[i]))\n",
        "\n",
        "runs = np.arange(1, len(ga_mean_fit)+1, 1)\n",
        "plt.plot(runs, ga_mean_fit, color='orange', linewidth = 1.5)\n",
        "#plt.plot(runs, ga_mean_acc, label = 'accuracy', linewidth = 0.5)\n",
        "#plt.legend()\n",
        "plt.xlabel('Interations')\n",
        "plt.ylabel('Fitness')\n",
        "plt.title('Convergence of Fitness over Iterations using GA')\n",
        "plt.savefig('Leukaemiamattest_ga.pdf')\n",
        "plt.savefig('Leukaemiamattest_ga.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uUwBwOPUiLQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
